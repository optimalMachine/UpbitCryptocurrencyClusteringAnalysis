{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYosVwSo+CiRzREvZlDP9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/optimalMachine/UpbitCryptocurrencyClusteringAnalysis/blob/main/Upbit_Cryptocurrency_Clustering_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 로깅 설정 - 기존 설정과 충돌 방지\n",
        "logger = logging.getLogger(__name__)\n",
        "if not logger.handlers:\n",
        "    handler = logging.StreamHandler()\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.addHandler(handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "# 영어 폰트 설정\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def validate_data_continuity(df, market, expected_interval_hours=4):\n",
        "    \"\"\"데이터 연속성 검증 및 보고\"\"\"\n",
        "    if len(df) < 2:\n",
        "        return True\n",
        "\n",
        "    time_diffs = df.index.to_series().diff()[1:]\n",
        "    expected_diff = pd.Timedelta(hours=expected_interval_hours)\n",
        "\n",
        "    # 허용 오차 (5%)\n",
        "    tolerance = 0.05\n",
        "    gaps = time_diffs[\n",
        "        (time_diffs < expected_diff * (1 - tolerance)) |\n",
        "        (time_diffs > expected_diff * (1 + tolerance))\n",
        "    ]\n",
        "\n",
        "    if len(gaps) > 0:\n",
        "        logger.warning(f\"{market}: 비정상적인 시간 간격 {len(gaps)}개 발견\")\n",
        "        # 큰 갭만 보고\n",
        "        large_gaps = gaps[gaps > expected_diff * 2]\n",
        "        if len(large_gaps) > 0:\n",
        "            logger.warning(f\"{market}: 큰 데이터 갭 {len(large_gaps)}개 (2배 이상 간격)\")\n",
        "\n",
        "    return len(gaps) == 0\n",
        "\n",
        "def get_upbit_candles(market, hours=4320, interval='240'):\n",
        "    \"\"\"\n",
        "    업비트에서 특정 코인의 과거 가격 데이터를 가져오는 함수 - 개선된 버전\n",
        "\n",
        "    Parameters:\n",
        "    - market: 마켓 코드 (예: 'KRW-BTC')\n",
        "    - hours: 가져올 데이터 기간 (시간 단위, 기본값: 4320시간 = 180일 = 6개월)\n",
        "    - interval: 캔들 간격 ('1', '3', '5', '15', '10', '30', '60', '240')\n",
        "    \"\"\"\n",
        "\n",
        "    # 4시간봉 = 240분\n",
        "    url = f\"https://api.upbit.com/v1/candles/minutes/{interval}\"\n",
        "\n",
        "    # API는 최대 200개까지만 반환하므로 여러 번 호출 필요\n",
        "    all_data = []\n",
        "    to_time = None\n",
        "    collected_times = set()  # 전체 수집된 시간을 추적\n",
        "\n",
        "    # 4시간봉 기준으로 계산\n",
        "    total_candles_needed = hours // 4\n",
        "\n",
        "    headers = {\"accept\": \"application/json\"}\n",
        "\n",
        "    # API 호출 횟수 제한 (최대 10회 = 2000개 캔들)\n",
        "    max_api_calls = 10\n",
        "    api_calls = 0\n",
        "\n",
        "    while len(all_data) < total_candles_needed and api_calls < max_api_calls:\n",
        "        params = {\n",
        "            'market': market,\n",
        "            'count': min(200, total_candles_needed - len(all_data))\n",
        "        }\n",
        "\n",
        "        if to_time:\n",
        "            params['to'] = to_time\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                if not data:\n",
        "                    break\n",
        "\n",
        "                # 중복 제거 로직 (개선됨)\n",
        "                new_data = []\n",
        "                for candle in data:\n",
        "                    candle_time = candle['candle_date_time_kst']\n",
        "                    if candle_time not in collected_times:\n",
        "                        new_data.append(candle)\n",
        "                        collected_times.add(candle_time)\n",
        "\n",
        "                if not new_data:\n",
        "                    logger.warning(f\"{market}: 새로운 데이터가 없습니다.\")\n",
        "                    break\n",
        "\n",
        "                # API 응답 데이터 정렬 확인\n",
        "                if len(new_data) > 1:\n",
        "                    first_time = pd.to_datetime(new_data[0]['candle_date_time_kst'])\n",
        "                    last_time = pd.to_datetime(new_data[-1]['candle_date_time_kst'])\n",
        "\n",
        "                    # 업비트 API는 보통 최신 데이터부터 반환 (내림차순)\n",
        "                    if first_time > last_time:  # 내림차순 (최신 → 과거)\n",
        "                        to_time = new_data[-1]['candle_date_time_utc']\n",
        "                    else:  # 오름차순 (과거 → 최신) - 드물지만 가능\n",
        "                        to_time = new_data[0]['candle_date_time_utc']\n",
        "\n",
        "                all_data.extend(new_data)\n",
        "\n",
        "                # API 호출 제한을 위한 대기\n",
        "                time.sleep(0.1)\n",
        "                api_calls += 1\n",
        "\n",
        "            else:\n",
        "                logger.warning(f\"API 오류 ({market}): {response.status_code}\")\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error for {market}: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    if all_data:\n",
        "        df = pd.DataFrame(all_data)\n",
        "        df['candle_date_time_kst'] = pd.to_datetime(df['candle_date_time_kst'])\n",
        "        df = df.set_index('candle_date_time_kst')\n",
        "        df = df.sort_index(ascending=True)\n",
        "\n",
        "        # 중복 인덱스 제거 (더 엄격하게)\n",
        "        df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "        # 데이터 연속성 체크\n",
        "        validate_data_continuity(df, market)\n",
        "\n",
        "        # 요청한 기간보다 적게 수집된 경우 알림\n",
        "        if len(df) < total_candles_needed * 0.8:  # 80% 미만\n",
        "            print(f\"  {market}: {len(df)}개 캔들만 수집됨 (목표: {total_candles_needed}개)\")\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def calculate_features(returns_df):\n",
        "    \"\"\"각 코인의 특성 계산 - 개선된 버전\"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    for coin in returns_df.columns:\n",
        "        coin_returns = returns_df[coin].dropna()\n",
        "\n",
        "        # 최소 데이터 체크\n",
        "        if len(coin_returns) < 60:  # 10일 최소\n",
        "            logger.warning(f\"{coin}: 데이터 부족 ({len(coin_returns)}개)\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # 기본 통계\n",
        "            features.loc[coin, 'mean_return'] = coin_returns.mean()\n",
        "            features.loc[coin, 'volatility'] = coin_returns.std()\n",
        "\n",
        "            # Sharpe Ratio 계산\n",
        "            if coin_returns.std() > 1e-8:\n",
        "                features.loc[coin, 'sharpe_ratio'] = (\n",
        "                    coin_returns.mean() / coin_returns.std() * np.sqrt(365 * 6)\n",
        "                )\n",
        "            else:\n",
        "                features.loc[coin, 'sharpe_ratio'] = 0\n",
        "\n",
        "            # 기타 통계량\n",
        "            features.loc[coin, 'skewness'] = coin_returns.skew()\n",
        "            features.loc[coin, 'kurtosis'] = coin_returns.kurtosis()\n",
        "            features.loc[coin, 'max_return'] = coin_returns.max()\n",
        "            features.loc[coin, 'min_return'] = coin_returns.min()\n",
        "            features.loc[coin, 'positive_periods_ratio'] = (coin_returns > 0).sum() / len(coin_returns)\n",
        "\n",
        "            # Max Drawdown - 안전한 계산\n",
        "            try:\n",
        "                cumulative = (1 + coin_returns).cumprod()\n",
        "                running_max = cumulative.expanding().max()\n",
        "                drawdown = (cumulative - running_max) / running_max\n",
        "                features.loc[coin, 'max_drawdown'] = drawdown.min()\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"{coin}: Max Drawdown 계산 실패\")\n",
        "                features.loc[coin, 'max_drawdown'] = np.nan\n",
        "\n",
        "            # Calmar Ratio\n",
        "            if abs(features.loc[coin, 'max_drawdown']) > 1e-8:\n",
        "                features.loc[coin, 'calmar_ratio'] = (\n",
        "                    features.loc[coin, 'mean_return'] * 365 * 6 / abs(features.loc[coin, 'max_drawdown'])\n",
        "                )\n",
        "            else:\n",
        "                features.loc[coin, 'calmar_ratio'] = 0\n",
        "\n",
        "            # 동적 기간 계산 (데이터 길이에 따라)\n",
        "            data_len = len(coin_returns)\n",
        "\n",
        "            # 일중 변동성 (최소 6개 필요)\n",
        "            if data_len >= 6:\n",
        "                daily_returns = coin_returns.rolling(6).sum().dropna()\n",
        "                if len(daily_returns) > 0:\n",
        "                    features.loc[coin, 'intraday_volatility'] = daily_returns.std()\n",
        "\n",
        "            # 주간 변동성 (최소 42개 필요)\n",
        "            if data_len >= 42:\n",
        "                weekly_returns = coin_returns.rolling(42).sum().dropna()\n",
        "                if len(weekly_returns) > 0:\n",
        "                    features.loc[coin, 'weekly_volatility'] = weekly_returns.std()\n",
        "\n",
        "            # 월간 트렌드 (최소 180개 필요)\n",
        "            if data_len >= 180:\n",
        "                monthly_return = coin_returns.iloc[-180:].sum()\n",
        "                features.loc[coin, 'monthly_trend'] = monthly_return\n",
        "\n",
        "            # 세션별 성과 (수정된 안전한 버전)\n",
        "            if hasattr(returns_df.index, 'hour') and data_len >= 30:\n",
        "                try:\n",
        "                    # returns_df에서 해당 코인의 데이터만 추출\n",
        "                    coin_series = returns_df[coin].dropna()\n",
        "\n",
        "                    if len(coin_series) > 0:\n",
        "                        coin_hours = coin_series.index.hour\n",
        "\n",
        "                        # 각 세션의 데이터 필터링\n",
        "                        asia_data = coin_series[coin_hours.isin([0, 4])]\n",
        "                        europe_data = coin_series[coin_hours.isin([8, 12])]\n",
        "                        us_data = coin_series[coin_hours.isin([16, 20])]\n",
        "\n",
        "                        # 세션별 수익률 계산\n",
        "                        if len(asia_data) > 10:\n",
        "                            features.loc[coin, 'asia_session_return'] = asia_data.mean()\n",
        "                        if len(europe_data) > 10:\n",
        "                            features.loc[coin, 'europe_session_return'] = europe_data.mean()\n",
        "                        if len(us_data) > 10:\n",
        "                            features.loc[coin, 'us_session_return'] = us_data.mean()\n",
        "                except Exception as e:\n",
        "                    logger.debug(f\"{coin}: 세션별 성과 계산 실패 - {str(e)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{coin} 특성 계산 실패: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # NaN 값 체크 및 제거\n",
        "    if features.isnull().any().any():\n",
        "        features_before = len(features)\n",
        "        # 핵심 컬럼에 NaN이 있는 행만 제거\n",
        "        essential_cols = ['mean_return', 'volatility', 'sharpe_ratio']\n",
        "        features = features.dropna(subset=essential_cols)\n",
        "        if features_before > len(features):\n",
        "            print(f\"⚠️ 필수 특성에 NaN 값이 있는 {features_before - len(features)}개 코인 제외\")\n",
        "\n",
        "    return features\n",
        "\n",
        "def classify_coins_by_data_quality(coin_data_info):\n",
        "    \"\"\"데이터 품질에 따른 코인 분류\"\"\"\n",
        "    high_quality = []    # 90% 이상 (972개+)\n",
        "    medium_quality = []  # 50-90% (540-972개)\n",
        "    low_quality = []     # 50% 미만 (540개 미만)\n",
        "\n",
        "    target_candles = 1080  # 6개월 목표\n",
        "\n",
        "    for coin, count in coin_data_info.items():\n",
        "        if count >= target_candles * 0.9:\n",
        "            high_quality.append(coin)\n",
        "        elif count >= target_candles * 0.5:\n",
        "            medium_quality.append(coin)\n",
        "        else:\n",
        "            low_quality.append(coin)\n",
        "\n",
        "    return {\n",
        "        'high': high_quality,\n",
        "        'medium': medium_quality,\n",
        "        'low': low_quality\n",
        "    }\n",
        "\n",
        "def get_all_krw_markets():\n",
        "    \"\"\"업비트의 모든 KRW 마켓 코인 목록을 가져오는 함수\"\"\"\n",
        "    url = \"https://api.upbit.com/v1/market/all\"\n",
        "    headers = {\"accept\": \"application/json\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            markets = response.json()\n",
        "            krw_coins = []\n",
        "\n",
        "            for market in markets:\n",
        "                if market['market'].startswith('KRW-'):\n",
        "                    coin_symbol = market['market'].split('-')[1]\n",
        "                    krw_coins.append(coin_symbol)\n",
        "\n",
        "            return krw_coins\n",
        "        else:\n",
        "            return []\n",
        "    except Exception as e:\n",
        "        logger.error(f\"마켓 목록 가져오기 실패: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def find_common_index_efficient(returns_data):\n",
        "    \"\"\"메모리 효율적인 공통 인덱스 찾기\"\"\"\n",
        "    if not returns_data:\n",
        "        return pd.DatetimeIndex([])\n",
        "\n",
        "    # 첫 번째 코인의 인덱스를 기준으로\n",
        "    common_dates = None\n",
        "    min_required = 60  # 최소 요구 데이터\n",
        "\n",
        "    for i, (coin, returns) in enumerate(returns_data.items()):\n",
        "        if common_dates is None:\n",
        "            common_dates = set(returns.index)\n",
        "        else:\n",
        "            # 교집합 업데이트\n",
        "            common_dates &= set(returns.index)\n",
        "\n",
        "        # 공통 날짜가 너무 적으면 조기 종료\n",
        "        if len(common_dates) < min_required:\n",
        "            logger.warning(f\"공통 날짜가 너무 적습니다: {len(common_dates)}개 (처리된 코인: {i+1}개)\")\n",
        "            break\n",
        "\n",
        "    if common_dates:\n",
        "        return pd.DatetimeIndex(sorted(list(common_dates)))\n",
        "    else:\n",
        "        return pd.DatetimeIndex([])\n",
        "\n",
        "def get_multiple_coins_data(coin_list, hours=4320, max_coins=None):\n",
        "    \"\"\"\n",
        "    여러 코인의 데이터를 한번에 가져오는 함수 - 개선된 버전\n",
        "    \"\"\"\n",
        "    returns_data = {}\n",
        "    price_data = {}\n",
        "    failed_coins = []\n",
        "    coin_data_info = {}  # 각 코인의 데이터 개수 저장\n",
        "\n",
        "    # 최대 코인 수 제한 (옵션)\n",
        "    if max_coins:\n",
        "        coin_list = coin_list[:max_coins]\n",
        "\n",
        "    total_coins = len(coin_list)\n",
        "    print(f\"총 {total_coins}개 코인의 4시간봉 데이터 수집 시작...\")\n",
        "    print(f\"수집 기간: 약 {hours//24}일 ({hours}시간) = {hours//24//30:.1f}개월\")\n",
        "    print(f\"예상 캔들 수: 약 {hours//4}개\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 배치 처리를 위한 설정\n",
        "    batch_size = 20 if total_coins > 100 else min(total_coins, 30)\n",
        "\n",
        "    for batch_start in range(0, total_coins, batch_size):\n",
        "        batch_end = min(batch_start + batch_size, total_coins)\n",
        "        batch_coins = coin_list[batch_start:batch_end]\n",
        "\n",
        "        print(f\"\\n배치 {batch_start//batch_size + 1}/{(total_coins-1)//batch_size + 1} 처리 중...\")\n",
        "\n",
        "        for idx, coin in enumerate(batch_coins):\n",
        "            global_idx = batch_start + idx\n",
        "            market = f'KRW-{coin}'\n",
        "\n",
        "            # 진행상황 표시\n",
        "            if (global_idx + 1) % 5 == 0 or global_idx == 0:\n",
        "                print(f\"진행률: {global_idx+1}/{total_coins} ({(global_idx+1)/total_coins*100:.1f}%)\")\n",
        "\n",
        "            try:\n",
        "                df = get_upbit_candles(market, hours=hours, interval='240')\n",
        "                if df is not None and len(df) > 60:  # 최소 60개 캔들 (10일) 이상\n",
        "                    # 데이터 정렬 확인\n",
        "                    df = df.sort_index(ascending=True)\n",
        "\n",
        "                    # 수익률 계산\n",
        "                    returns = df['trade_price'].pct_change().dropna()\n",
        "\n",
        "                    if len(returns) > 60 and returns.std() > 1e-8:\n",
        "                        returns_data[coin] = returns\n",
        "                        price_data[coin] = df['trade_price']\n",
        "                        coin_data_info[coin] = len(returns)\n",
        "                    else:\n",
        "                        failed_coins.append(coin)\n",
        "                else:\n",
        "                    failed_coins.append(coin)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"{coin} 수집 실패: {str(e)}\")\n",
        "                failed_coins.append(coin)\n",
        "\n",
        "            # API 호출 제한을 위한 대기\n",
        "            time.sleep(0.3)\n",
        "\n",
        "        # 배치 간 추가 대기\n",
        "        if batch_end < total_coins:\n",
        "            print(f\"다음 배치 처리를 위해 잠시 대기 중...\")\n",
        "            time.sleep(3)\n",
        "\n",
        "    print(f\"\\n✅ 데이터 수집 완료!\")\n",
        "    print(f\"성공: {len(returns_data)}개 / 실패: {len(failed_coins)}개\")\n",
        "\n",
        "    if failed_coins and len(failed_coins) <= 20:\n",
        "        print(f\"실패한 코인: {', '.join(failed_coins)}\")\n",
        "    elif failed_coins:\n",
        "        print(f\"실패한 코인: {', '.join(failed_coins[:20])} 외 {len(failed_coins)-20}개\")\n",
        "\n",
        "    # 데이터 품질 분류\n",
        "    quality_groups = classify_coins_by_data_quality(coin_data_info)\n",
        "    print(f\"\\n📊 데이터 품질 분석:\")\n",
        "    print(f\"  - 고품질 (90%+): {len(quality_groups['high'])}개\")\n",
        "    print(f\"  - 중품질 (50-90%): {len(quality_groups['medium'])}개\")\n",
        "    print(f\"  - 저품질 (<50%): {len(quality_groups['low'])}개\")\n",
        "\n",
        "    # DataFrame 생성 - 메모리 효율적인 공통 인덱스 찾기\n",
        "    if returns_data:\n",
        "        # 효율적인 공통 인덱스 계산\n",
        "        common_index = find_common_index_efficient(returns_data)\n",
        "\n",
        "        print(f\"\\n공통 인덱스 개수: {len(common_index)}\")\n",
        "\n",
        "        # 공통 인덱스로 DataFrame 생성\n",
        "        returns_dict_aligned = {}\n",
        "        price_dict_aligned = {}\n",
        "\n",
        "        # 최소 360개 이상의 공통 데이터 선호\n",
        "        min_required = 360 if len(common_index) >= 360 else 60\n",
        "\n",
        "        if len(common_index) >= min_required:\n",
        "            for coin, returns in returns_data.items():\n",
        "                try:\n",
        "                    returns_dict_aligned[coin] = returns[common_index]\n",
        "                    if coin in price_data:\n",
        "                        price_dict_aligned[coin] = price_data[coin][common_index]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"{coin}: 공통 인덱스 적용 실패 - {str(e)}\")\n",
        "        else:\n",
        "            print(f\"⚠️ 공통 인덱스 데이터가 부족합니다: {len(common_index)}개\")\n",
        "            # 각 코인별로 가능한 데이터 사용\n",
        "            for coin, returns in returns_data.items():\n",
        "                if len(returns) >= min_required:\n",
        "                    returns_dict_aligned[coin] = returns\n",
        "                    if coin in price_data:\n",
        "                        price_dict_aligned[coin] = price_data[coin]\n",
        "\n",
        "        returns_df = pd.DataFrame(returns_dict_aligned)\n",
        "        price_df = pd.DataFrame(price_dict_aligned)\n",
        "\n",
        "        # 인덱스 정렬 및 데이터 정렬\n",
        "        returns_df = returns_df.sort_index(ascending=True)\n",
        "        price_df = price_df.sort_index(ascending=True)\n",
        "\n",
        "        # 컬럼도 알파벳 순으로 정렬 (재현성을 위해)\n",
        "        returns_df = returns_df.reindex(sorted(returns_df.columns), axis=1)\n",
        "        price_df = price_df.reindex(sorted(price_df.columns), axis=1)\n",
        "\n",
        "        print(f\"\\n수집된 공통 4시간봉 개수: {len(returns_df)}개\")\n",
        "        if len(returns_df) > 0:\n",
        "            print(f\"공통 수집 기간: {returns_df.index[0].strftime('%Y-%m-%d %H:%M')} ~ {returns_df.index[-1].strftime('%Y-%m-%d %H:%M')}\")\n",
        "            actual_days = (returns_df.index[-1] - returns_df.index[0]).days\n",
        "            print(f\"실제 수집 일수: {actual_days}일 ({actual_days/30:.1f}개월)\")\n",
        "    else:\n",
        "        returns_df = pd.DataFrame()\n",
        "        price_df = pd.DataFrame()\n",
        "\n",
        "    return returns_df, price_df, quality_groups\n",
        "\n",
        "def adaptive_clustering(features_df, max_k=10):\n",
        "    \"\"\"데이터 특성에 맞는 최적 클러스터 수 찾기 - 수정된 버전\"\"\"\n",
        "    n_samples = len(features_df)\n",
        "\n",
        "    # 샘플 수에 따라 최대 클러스터 조정\n",
        "    max_k = min(max_k, n_samples // 10)\n",
        "    max_k = max(max_k, 3)\n",
        "\n",
        "    # DataFrame이면 컬럼 체크 가능\n",
        "    if isinstance(features_df, pd.DataFrame) and 'volatility' in features_df.columns:\n",
        "        volatility_std = features_df['volatility'].std()\n",
        "        if volatility_std > 0.02:  # 변동성 차이가 크면\n",
        "            max_k = min(max_k + 2, n_samples // 8)\n",
        "\n",
        "    return max_k\n",
        "\n",
        "def find_optimal_clusters(features_scaled, features_df=None, max_k=10):\n",
        "    \"\"\"최적의 클러스터 수 찾기 - 개선된 버전\"\"\"\n",
        "    n_samples = len(features_scaled)\n",
        "\n",
        "    if features_df is not None:\n",
        "        max_k = adaptive_clustering(features_df, max_k=max_k)\n",
        "    else:\n",
        "        max_k = min(max_k, n_samples // 10)\n",
        "        max_k = max(max_k, 3)\n",
        "\n",
        "    inertias = []\n",
        "    silhouette_scores = []\n",
        "\n",
        "    for k in range(2, max_k+1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        kmeans.fit(features_scaled)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "\n",
        "        # 안전한 silhouette score 계산\n",
        "        try:\n",
        "            score = silhouette_score(features_scaled, kmeans.labels_)\n",
        "            silhouette_scores.append(score)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Silhouette score 계산 실패 (k={k}): {str(e)}\")\n",
        "            silhouette_scores.append(-1)\n",
        "\n",
        "    return inertias, silhouette_scores\n",
        "\n",
        "def perform_clustering_analysis(returns_df):\n",
        "    \"\"\"클러스터링 분석 수행 - 개선된 버전\"\"\"\n",
        "\n",
        "    # 데이터 검증\n",
        "    if returns_df.empty or len(returns_df.columns) < 3:\n",
        "        print(\"❌ 분석하기에 충분한 데이터가 없습니다. (최소 3개 이상의 코인 필요)\")\n",
        "        return None, None\n",
        "\n",
        "    # 특성 계산\n",
        "    features = calculate_features(returns_df)\n",
        "\n",
        "    # features가 비어있는지 확인\n",
        "    if features.empty:\n",
        "        print(\"❌ 유효한 특성을 계산할 수 없습니다.\")\n",
        "        return None, None\n",
        "\n",
        "    # features와 returns_df의 인덱스 일치 확인\n",
        "    common_coins = list(set(returns_df.columns) & set(features.index))\n",
        "    if len(common_coins) < 3:\n",
        "        print(\"❌ 유효한 특성을 가진 코인이 부족합니다.\")\n",
        "        return None, None\n",
        "\n",
        "    # 공통 코인만 사용 (정렬하여 재현성 확보)\n",
        "    common_coins = sorted(common_coins)\n",
        "    features = features.loc[common_coins]\n",
        "    returns_df = returns_df[common_coins]\n",
        "\n",
        "    # 특성 정규화\n",
        "    scaler = StandardScaler()\n",
        "    try:\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 특성 정규화 실패: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "    # 최적 클러스터 수 찾기 - features DataFrame 전달\n",
        "    inertias, silhouette_scores = find_optimal_clusters(features_scaled, features_df=features, max_k=8)\n",
        "\n",
        "    # 시각화를 위한 Figure 생성\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # 1. Elbow Method\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    ax1.plot(range(2, len(inertias)+2), inertias, 'bo-')\n",
        "    ax1.set_xlabel('Number of Clusters')\n",
        "    ax1.set_ylabel('Inertia')\n",
        "    ax1.set_title('Elbow Method')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Silhouette Score\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    valid_scores = [s for s in silhouette_scores if s != -1]\n",
        "    if valid_scores:\n",
        "        ax2.plot(range(2, len(silhouette_scores)+2), silhouette_scores, 'ro-')\n",
        "        ax2.set_xlabel('Number of Clusters')\n",
        "        ax2.set_ylabel('Silhouette Score')\n",
        "        ax2.set_title('Silhouette Score by Number of Clusters')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # 최적 클러스터 수 결정 (수정된 로직)\n",
        "        if valid_scores:\n",
        "            # silhouette_scores에서 최대값(valid_scores의 최대값)의 인덱스 찾기\n",
        "            max_score = max(valid_scores)\n",
        "            optimal_k = silhouette_scores.index(max_score) + 2\n",
        "        else:\n",
        "            optimal_k = 3\n",
        "    else:\n",
        "        optimal_k = 3  # 기본값\n",
        "        ax2.text(0.5, 0.5, 'Silhouette Score calculation failed', ha='center', va='center')\n",
        "\n",
        "    print(f\"\\n📊 클러스터링 분석 결과:\")\n",
        "    print(\"=\" * 60)\n",
        "    if valid_scores:\n",
        "        print(f\"최적 클러스터 수: {optimal_k}개 (Silhouette Score: {max(valid_scores):.3f})\")\n",
        "    else:\n",
        "        print(f\"최적 클러스터 수: {optimal_k}개 (Silhouette Score: N/A)\")\n",
        "\n",
        "    # K-means 클러스터링 수행\n",
        "    try:\n",
        "        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "        clusters = kmeans.fit_predict(features_scaled)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 클러스터링 실패: {str(e)}\")\n",
        "        plt.close(fig)\n",
        "        return None, None\n",
        "\n",
        "    # 클러스터 결과 저장\n",
        "    cluster_df = pd.DataFrame({\n",
        "        'Coin': features.index,\n",
        "        'Cluster': clusters\n",
        "    })\n",
        "\n",
        "    # PCA로 차원 축소 (시각화용) - 수정된 버전\n",
        "    try:\n",
        "        # 최소 2개 이상의 특성이 있을 때만 PCA 수행\n",
        "        if features.shape[1] >= 2:\n",
        "            n_components = min(2, features.shape[1])\n",
        "            pca = PCA(n_components=n_components)\n",
        "            features_pca = pca.fit_transform(features_scaled)\n",
        "            pca_success = True\n",
        "        else:\n",
        "            # 특성이 1개인 경우 처리\n",
        "            pca_success = False\n",
        "            features_pca = np.column_stack([features_scaled[:, 0], np.zeros(len(features_scaled))])\n",
        "            n_components = 1\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"PCA 변환 경고: {str(e)}\")\n",
        "        pca_success = False\n",
        "        if features_scaled.shape[1] >= 2:\n",
        "            features_pca = features_scaled[:, :2]\n",
        "        else:\n",
        "            features_pca = np.column_stack([features_scaled[:, 0], np.zeros(len(features_scaled))])\n",
        "        n_components = 1\n",
        "\n",
        "    # 3. 클러스터 시각화 (PCA) - 수정된 버전\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    if features_pca.shape[1] >= 2:\n",
        "        scatter = ax3.scatter(features_pca[:, 0], features_pca[:, 1],\n",
        "                             c=clusters, cmap='viridis', s=200, alpha=0.6)\n",
        "\n",
        "        # 코인 이름 표시 (많은 경우 상위 코인만)\n",
        "        if len(features.index) > 30:\n",
        "            # 샤프비율 기준 상위 30개\n",
        "            if 'sharpe_ratio' in features.columns:\n",
        "                top_coins = features.nlargest(30, 'sharpe_ratio').index\n",
        "            else:\n",
        "                top_coins = features.index[:30]\n",
        "\n",
        "            for i, coin in enumerate(features.index):\n",
        "                if coin in top_coins:\n",
        "                    ax3.annotate(coin, (features_pca[i, 0], features_pca[i, 1]),\n",
        "                                fontsize=8, ha='center', va='center')\n",
        "        else:\n",
        "            for i, coin in enumerate(features.index):\n",
        "                ax3.annotate(coin, (features_pca[i, 0], features_pca[i, 1]),\n",
        "                            fontsize=10, ha='center', va='center')\n",
        "\n",
        "        if pca_success and n_components == 2:\n",
        "            ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "            ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "        else:\n",
        "            ax3.set_xlabel('Feature 1')\n",
        "            ax3.set_ylabel('Feature 2')\n",
        "\n",
        "        ax3.set_title('Cryptocurrency Clusters (PCA)')\n",
        "        plt.colorbar(scatter, ax=ax3)\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'PCA visualization not available\\n(Insufficient features)',\n",
        "                ha='center', va='center', fontsize=12)\n",
        "        ax3.set_title('Cryptocurrency Clusters')\n",
        "\n",
        "    # 4. 특성별 히트맵\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    features_with_cluster = features.copy()\n",
        "    features_with_cluster['Cluster'] = clusters\n",
        "    features_sorted = features_with_cluster.sort_values('Cluster')\n",
        "\n",
        "    # 표시할 특성 선택 (존재하는 특성만)\n",
        "    display_features = ['mean_return', 'volatility', 'sharpe_ratio', 'skewness',\n",
        "                       'positive_periods_ratio', 'max_drawdown']\n",
        "    display_features = [f for f in display_features if f in features.columns]\n",
        "\n",
        "    # 히트맵 그리기\n",
        "    if display_features and len(features_sorted) > 0:\n",
        "        if len(features_sorted) > 50:\n",
        "            sns.heatmap(features_sorted[display_features].T,\n",
        "                        cmap='coolwarm', center=0,\n",
        "                        xticklabels=False,\n",
        "                        yticklabels=display_features,\n",
        "                        ax=ax4, cbar_kws={'shrink': 0.8})\n",
        "        else:\n",
        "            sns.heatmap(features_sorted[display_features].T,\n",
        "                        cmap='coolwarm', center=0,\n",
        "                        xticklabels=features_sorted.index,\n",
        "                        yticklabels=display_features,\n",
        "                        ax=ax4, cbar_kws={'shrink': 0.8})\n",
        "            plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'No features to display', ha='center', va='center')\n",
        "\n",
        "    ax4.set_title('Feature Heatmap by Coin')\n",
        "\n",
        "    # 5. 클러스터별 평균 특성\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    if display_features:\n",
        "        cluster_means = features_with_cluster.groupby('Cluster')[display_features].mean()\n",
        "\n",
        "        # 안전한 정규화\n",
        "        cluster_means_std = cluster_means.std()\n",
        "        cluster_means_std[cluster_means_std == 0] = 1  # 0으로 나누기 방지\n",
        "        cluster_means_normalized = (cluster_means - cluster_means.mean()) / cluster_means_std\n",
        "\n",
        "        sns.heatmap(cluster_means_normalized.T, annot=True, fmt='.2f',\n",
        "                    cmap='RdBu_r', center=0, ax=ax5,\n",
        "                    xticklabels=[f'Cluster {i}' for i in sorted(cluster_df['Cluster'].unique())],\n",
        "                    yticklabels=display_features,\n",
        "                    cbar_kws={'shrink': 0.8})\n",
        "    else:\n",
        "        ax5.text(0.5, 0.5, 'No features to analyze', ha='center', va='center')\n",
        "\n",
        "    ax5.set_title('Normalized Mean Features by Cluster')\n",
        "\n",
        "    # 6. 수익률-변동성 산점도\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    if 'volatility' in features.columns and 'mean_return' in features.columns:\n",
        "        scatter2 = ax6.scatter(features['volatility']*100, features['mean_return']*100,\n",
        "                              c=clusters, cmap='viridis', s=200, alpha=0.6)\n",
        "\n",
        "        # 레이블 표시 (겹침 방지)\n",
        "        if len(features.index) <= 20:\n",
        "            for i, coin in enumerate(features.index):\n",
        "                ax6.annotate(coin, (features['volatility'].iloc[i]*100,\n",
        "                                   features['mean_return'].iloc[i]*100),\n",
        "                            fontsize=9, ha='left', va='bottom')\n",
        "        else:\n",
        "            # 각 클러스터에서 대표 코인만 표시\n",
        "            for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "                cluster_coins = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "                if len(cluster_coins) > 0:\n",
        "                    cluster_features = features.loc[cluster_coins]\n",
        "                    if len(cluster_features) > 0 and 'sharpe_ratio' in cluster_features.columns:\n",
        "                        best_coin = cluster_features.nlargest(1, 'sharpe_ratio').index[0]\n",
        "                        idx = features.index.get_loc(best_coin)\n",
        "                        ax6.annotate(best_coin,\n",
        "                                   (features['volatility'].iloc[idx]*100,\n",
        "                                    features['mean_return'].iloc[idx]*100),\n",
        "                                   fontsize=9, ha='left', va='bottom',\n",
        "                                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "        ax6.set_xlabel('4H Volatility (%)')\n",
        "        ax6.set_ylabel('Mean 4H Return (%)')\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter2, ax=ax6)\n",
        "    else:\n",
        "        ax6.text(0.5, 0.5, 'Risk-return data not available', ha='center', va='center')\n",
        "\n",
        "    ax6.set_title('Risk-Return Profile by Cluster')\n",
        "\n",
        "    # 7. 클러스터별 박스플롯 (수익률)\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    cluster_returns_list = []\n",
        "    cluster_labels = []\n",
        "\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        coins_in_cluster = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        valid_coins = [coin for coin in coins_in_cluster if coin in returns_df.columns]\n",
        "\n",
        "        if valid_coins:\n",
        "            cluster_data = []\n",
        "            for coin in valid_coins:\n",
        "                coin_returns = returns_df[coin].dropna().values\n",
        "                if len(coin_returns) > 0:\n",
        "                    cluster_data.extend(coin_returns)\n",
        "\n",
        "            if cluster_data:\n",
        "                cluster_returns_list.append(cluster_data)\n",
        "                cluster_labels.append(f'Cluster {cluster}')\n",
        "\n",
        "    if cluster_returns_list:\n",
        "        bp = ax7.boxplot(cluster_returns_list, labels=cluster_labels, patch_artist=True)\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(cluster_returns_list)))\n",
        "        for patch, color in zip(bp['boxes'], colors):\n",
        "            patch.set_facecolor(color)\n",
        "        ax7.set_ylabel('4H Returns')\n",
        "        ax7.set_title('Returns Distribution by Cluster')\n",
        "        ax7.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax7.text(0.5, 0.5, 'No data available', ha='center', va='center')\n",
        "        ax7.set_title('Returns Distribution by Cluster')\n",
        "\n",
        "    # 8. 상관관계 히트맵 (클러스터별 정렬)\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    valid_coins = [coin for coin in cluster_df['Coin'].values if coin in returns_df.columns]\n",
        "    cluster_df_valid = cluster_df[cluster_df['Coin'].isin(valid_coins)]\n",
        "\n",
        "    if len(cluster_df_valid) > 0:\n",
        "        sorted_coins = cluster_df_valid.sort_values('Cluster')['Coin'].values\n",
        "        corr_sorted = returns_df[sorted_coins].corr()\n",
        "\n",
        "        # 상관관계 히트맵 그리기\n",
        "        if len(sorted_coins) > 30:\n",
        "            sns.heatmap(corr_sorted, cmap='coolwarm', center=0,\n",
        "                        square=True, ax=ax8,\n",
        "                        xticklabels=False, yticklabels=False,\n",
        "                        cbar_kws={'shrink': 0.8})\n",
        "        else:\n",
        "            mask = np.zeros_like(corr_sorted, dtype=bool)\n",
        "            mask[np.triu_indices_from(mask, k=1)] = True\n",
        "            sns.heatmap(corr_sorted, mask=mask, cmap='coolwarm', center=0,\n",
        "                        square=True, ax=ax8,\n",
        "                        xticklabels=sorted_coins, yticklabels=sorted_coins,\n",
        "                        cbar_kws={'shrink': 0.8})\n",
        "            plt.setp(ax8.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "            plt.setp(ax8.yaxis.get_majorticklabels(), rotation=0)\n",
        "\n",
        "        ax8.set_title('Correlation Matrix (Sorted by Cluster)')\n",
        "    else:\n",
        "        ax8.text(0.5, 0.5, 'No data available', ha='center', va='center')\n",
        "        ax8.set_title('Correlation Matrix')\n",
        "\n",
        "    # 9. 클러스터 크기 파이 차트\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    cluster_sizes = cluster_df['Cluster'].value_counts().sort_index()\n",
        "\n",
        "    if len(cluster_sizes) > 0:\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(cluster_sizes)))\n",
        "\n",
        "        # 올바른 클러스터 번호와 크기 사용\n",
        "        labels = [f'Cluster {cluster_num}\\n({size} coins)'\n",
        "                 for cluster_num, size in cluster_sizes.items()]\n",
        "\n",
        "        wedges, texts, autotexts = ax9.pie(cluster_sizes.values,\n",
        "                                            labels=labels,\n",
        "                                            autopct='%1.1f%%',\n",
        "                                            startangle=90,\n",
        "                                            colors=colors)\n",
        "\n",
        "        # 텍스트 스타일 조정\n",
        "        for text in texts:\n",
        "            text.set_fontsize(10)\n",
        "        for autotext in autotexts:\n",
        "            autotext.set_color('white')\n",
        "            autotext.set_fontsize(9)\n",
        "            autotext.set_weight('bold')\n",
        "    else:\n",
        "        ax9.text(0.5, 0.5, 'No clusters to display', ha='center', va='center')\n",
        "\n",
        "    ax9.set_title('Cluster Size Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)  # 메모리 정리\n",
        "\n",
        "    # 클러스터별 상세 정보 출력\n",
        "    print(\"\\n🔍 클러스터별 코인 그룹:\")\n",
        "    print(\"=\" * 60)\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        coins_in_cluster = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        print(f\"\\n클러스터 {cluster} ({len(coins_in_cluster)}개 코인):\")\n",
        "\n",
        "        if len(coins_in_cluster) <= 20:\n",
        "            print(f\"  코인: {', '.join(coins_in_cluster)}\")\n",
        "        else:\n",
        "            print(f\"  코인: {', '.join(coins_in_cluster[:10])} ... 외 {len(coins_in_cluster)-10}개\")\n",
        "\n",
        "        # 클러스터 특성 요약\n",
        "        if len(coins_in_cluster) > 0:\n",
        "            valid_coins = [coin for coin in coins_in_cluster if coin in features.index]\n",
        "            if valid_coins:\n",
        "                cluster_features = features.loc[valid_coins].mean()\n",
        "                print(f\"  - 평균 4시간 수익률: {cluster_features['mean_return']*100:.4f}%\")\n",
        "                print(f\"  - 평균 변동성: {cluster_features['volatility']*100:.4f}%\")\n",
        "                print(f\"  - 평균 샤프 비율: {cluster_features['sharpe_ratio']:.4f}\")\n",
        "                print(f\"  - 평균 양의 수익 구간 비율: {cluster_features['positive_periods_ratio']*100:.1f}%\")\n",
        "                if 'max_drawdown' in cluster_features and not np.isnan(cluster_features['max_drawdown']):\n",
        "                    print(f\"  - 평균 최대 낙폭: {cluster_features['max_drawdown']*100:.2f}%\")\n",
        "                if 'intraday_volatility' in cluster_features and not np.isnan(cluster_features['intraday_volatility']):\n",
        "                    print(f\"  - 평균 일중 변동성: {cluster_features['intraday_volatility']*100:.2f}%\")\n",
        "\n",
        "    # 특성 중요도\n",
        "    if pca_success and n_components >= 2:\n",
        "        print(\"\\n📈 클러스터 구분에 중요한 특성:\")\n",
        "        print(\"=\" * 60)\n",
        "        feature_importance = np.abs(pca.components_).mean(axis=0)\n",
        "        feature_names = list(features.columns)\n",
        "        if len(feature_names) == len(feature_importance):\n",
        "            importance_df = pd.DataFrame({\n",
        "                'Feature': feature_names,\n",
        "                'Importance': feature_importance\n",
        "            }).sort_values('Importance', ascending=False)\n",
        "\n",
        "            for idx, row in importance_df.head(8).iterrows():\n",
        "                print(f\"  {row['Feature']}: {row['Importance']:.3f}\")\n",
        "\n",
        "    return cluster_df, features\n",
        "\n",
        "# 메인 실행 코드\n",
        "if __name__ == \"__main__\":\n",
        "    # 모든 KRW 마켓 코인 가져오기\n",
        "    print(\"업비트 KRW 마켓 코인 목록을 가져오는 중...\")\n",
        "    all_krw_coins = get_all_krw_markets()\n",
        "\n",
        "    if not all_krw_coins:\n",
        "        print(\"❌ KRW 마켓 코인 목록을 가져올 수 없습니다.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\n📊 업비트 KRW 마켓 분석\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"총 KRW 마켓 코인 수: {len(all_krw_coins)}개\")\n",
        "\n",
        "    # 분석 옵션 선택\n",
        "    print(\"\\n분석 옵션을 선택하세요:\")\n",
        "    print(\"1. 전체 코인 분석 (시간이 오래 걸림)\")\n",
        "    print(\"2. 상위 N개 코인만 분석\")\n",
        "    print(\"3. 주요 코인만 분석 (추천)\")\n",
        "\n",
        "    # 기본값: 전체 코인 분석\n",
        "    choice = input(\"\\n선택 (기본값: 3): \").strip() or \"3\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        coin_list = all_krw_coins\n",
        "        print(f\"\\n전체 {len(coin_list)}개 코인을 분석합니다.\")\n",
        "    elif choice == \"2\":\n",
        "        n = int(input(\"분석할 코인 수를 입력하세요 (예: 50): \"))\n",
        "        coin_list = all_krw_coins[:n]\n",
        "        print(f\"\\n상위 {n}개 코인을 분석합니다.\")\n",
        "    else:\n",
        "        # 주요 코인 목록 (거래량 상위 + 인기 코인)\n",
        "        major_coins = ['BTC', 'ETH', 'XRP', 'ADA', 'SOL', 'DOGE', 'AVAX', 'MATIC',\n",
        "                      'LINK', 'DOT', 'ATOM', 'UNI', 'BCH', 'LTC', 'ETC', 'ALGO',\n",
        "                      'SAND', 'MANA', 'AXS', 'THETA', 'EOS', 'TRX', 'XLM', 'VET',\n",
        "                      'HBAR', 'EGLD', 'NEAR', 'FLOW', 'CHZ', 'ENJ', 'QTUM', 'NEO']\n",
        "        coin_list = [coin for coin in major_coins if coin in all_krw_coins]\n",
        "        print(f\"\\n주요 {len(coin_list)}개 코인을 분석합니다.\")\n",
        "\n",
        "    # 과거 데이터 기간 설정 (4시간봉 기준)\n",
        "    hours = 4320  # 180일 = 4320시간 = 6개월\n",
        "\n",
        "    print(f\"\\n업비트에서 {hours}시간({hours//24}일 = {hours//24//30:.1f}개월)간의 4시간봉 데이터를 수집합니다...\")\n",
        "    print(f\"예상 데이터 포인트: 약 {hours//4}개 (180일 × 6개/일)\")\n",
        "\n",
        "    # 데이터 수집 - 개선된 함수 사용\n",
        "    returns_df, price_df, quality_groups = get_multiple_coins_data(coin_list, hours=hours)\n",
        "\n",
        "    if returns_df is None or returns_df.empty:\n",
        "        print(\"❌ 데이터 수집에 실패했습니다.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\n✅ 분석 가능한 코인 수: {len(returns_df.columns)}개\")\n",
        "    print(f\"수집된 데이터 기간: {returns_df.index[0].strftime('%Y-%m-%d %H:%M')} ~ {returns_df.index[-1].strftime('%Y-%m-%d %H:%M')}\")\n",
        "    print(f\"총 4시간봉 개수: {len(returns_df)}개\")\n",
        "\n",
        "    # 클러스터링 분석 수행\n",
        "    cluster_df, features = perform_clustering_analysis(returns_df)\n",
        "\n",
        "    if cluster_df is None or features is None:\n",
        "        print(\"❌ 클러스터링 분석에 실패했습니다.\")\n",
        "        exit()\n",
        "\n",
        "    # 클러스터별 대표 코인 추천\n",
        "    print(\"\\n🎯 클러스터별 대표 코인 추천:\")\n",
        "    print(\"=\" * 60)\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        cluster_coins = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        valid_coins = [coin for coin in cluster_coins if coin in features.index]\n",
        "\n",
        "        if valid_coins:\n",
        "            cluster_features = features.loc[valid_coins]\n",
        "\n",
        "            # 샤프 비율이 높은 상위 3개 코인\n",
        "            top_coins = cluster_features.nlargest(min(3, len(cluster_features)), 'sharpe_ratio')\n",
        "            print(f\"\\n클러스터 {cluster} 추천 코인:\")\n",
        "            for coin in top_coins.index:\n",
        "                sharpe = top_coins.loc[coin, 'sharpe_ratio']\n",
        "                volatility = top_coins.loc[coin, 'volatility'] * 100\n",
        "                mean_return = top_coins.loc[coin, 'mean_return'] * 100\n",
        "                print(f\"  - {coin}: 샤프비율 {sharpe:.3f}, 4시간 수익률 {mean_return:.3f}%, 변동성 {volatility:.3f}%\")\n",
        "\n",
        "    # 포트폴리오 구성 제안\n",
        "    print(\"\\n💡 포트폴리오 구성 제안:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"1. 각 클러스터에서 샤프 비율이 높은 1-2개 코인 선택\")\n",
        "    print(\"2. 전체 포트폴리오의 5-10개 코인으로 구성\")\n",
        "    print(\"3. BTC와 ETH는 안정성을 위해 포함 권장\")\n",
        "    print(\"4. 각 코인의 비중은 리스크 허용도에 따라 조정\")\n",
        "\n",
        "    # 추가 분석: 포트폴리오 최적화 예시\n",
        "    print(\"\\n🎲 샘플 포트폴리오 구성:\")\n",
        "    print(\"=\" * 60)\n",
        "    sample_portfolio = []\n",
        "\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        cluster_coins = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        valid_coins = [coin for coin in cluster_coins if coin in features.index]\n",
        "\n",
        "        if valid_coins:\n",
        "            cluster_features = features.loc[valid_coins]\n",
        "            # 각 클러스터에서 샤프비율 최고 코인 선택\n",
        "            best_coin = cluster_features.nlargest(1, 'sharpe_ratio').index[0]\n",
        "            sample_portfolio.append(best_coin)\n",
        "\n",
        "    # BTC, ETH가 없으면 추가\n",
        "    if 'BTC' in returns_df.columns and 'BTC' not in sample_portfolio:\n",
        "        sample_portfolio.insert(0, 'BTC')\n",
        "    if 'ETH' in returns_df.columns and 'ETH' not in sample_portfolio:\n",
        "        sample_portfolio.insert(1, 'ETH')\n",
        "\n",
        "    # 최대 10개로 제한\n",
        "    sample_portfolio = sample_portfolio[:10]\n",
        "\n",
        "    print(f\"추천 포트폴리오 구성 ({len(sample_portfolio)}개 코인):\")\n",
        "    total_sharpe = 0\n",
        "    for i, coin in enumerate(sample_portfolio):\n",
        "        if coin in features.index:\n",
        "            sharpe = features.loc[coin, 'sharpe_ratio']\n",
        "            volatility = features.loc[coin, 'volatility'] * 100\n",
        "            total_sharpe += sharpe\n",
        "            print(f\"  {i+1}. {coin} (샤프비율: {sharpe:.3f}, 변동성: {volatility:.2f}%)\")\n",
        "\n",
        "    if len(sample_portfolio) > 0:\n",
        "        print(f\"\\n포트폴리오 평균 샤프비율: {total_sharpe/len(sample_portfolio):.3f}\")\n",
        "\n",
        "    # 분석 결과 저장 옵션\n",
        "    save = input(\"\\n분석 결과를 CSV로 저장하시겠습니까? (y/n): \").strip().lower()\n",
        "    if save == 'y':\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        try:\n",
        "            # 클러스터 결과 저장\n",
        "            cluster_df.to_csv(f'upbit_clustering_result_{timestamp}.csv',\n",
        "                             index=False, encoding='utf-8-sig')\n",
        "\n",
        "            # 특성 데이터 저장\n",
        "            features.to_csv(f'upbit_coin_features_{timestamp}.csv',\n",
        "                           encoding='utf-8-sig')\n",
        "\n",
        "            # 추천 포트폴리오 저장\n",
        "            portfolio_df = pd.DataFrame({\n",
        "                'Rank': range(1, len(sample_portfolio)+1),\n",
        "                'Coin': sample_portfolio,\n",
        "                'Sharpe_Ratio': [features.loc[coin, 'sharpe_ratio'] if coin in features.index else np.nan\n",
        "                               for coin in sample_portfolio],\n",
        "                '4H_Return_%': [features.loc[coin, 'mean_return']*100 if coin in features.index else np.nan\n",
        "                                 for coin in sample_portfolio],\n",
        "                '4H_Volatility_%': [features.loc[coin, 'volatility']*100 if coin in features.index else np.nan\n",
        "                                     for coin in sample_portfolio]\n",
        "            })\n",
        "            portfolio_df.to_csv(f'upbit_recommended_portfolio_{timestamp}.csv',\n",
        "                              index=False, encoding='utf-8-sig')\n",
        "\n",
        "            print(f\"\\n✅ 분석 결과가 저장되었습니다:\")\n",
        "            print(f\"  - 클러스터 결과: upbit_clustering_result_{timestamp}.csv\")\n",
        "            print(f\"  - 코인 특성: upbit_coin_features_{timestamp}.csv\")\n",
        "            print(f\"  - 추천 포트폴리오: upbit_recommended_portfolio_{timestamp}.csv\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"파일 저장 중 오류 발생: {str(e)}\")\n",
        "            print(f\"\\n❌ 파일 저장 중 오류 발생: {str(e)}\")\n",
        "\n",
        "    print(\"\\n📌 분석 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "GRGQZPtcElaJ",
        "outputId": "ff5991c9-755c-4330-b534-06e7aeeea81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "업비트 KRW 마켓 코인 목록을 가져오는 중...\n",
            "\n",
            "📊 업비트 KRW 마켓 분석\n",
            "============================================================\n",
            "총 KRW 마켓 코인 수: 179개\n",
            "\n",
            "분석 옵션을 선택하세요:\n",
            "1. 전체 코인 분석 (시간이 오래 걸림)\n",
            "2. 상위 N개 코인만 분석\n",
            "3. 주요 코인만 분석 (추천)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-313239679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;31m# 기본값: 전체 코인 분석\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n선택 (기본값: 3): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qxyCYbOE9z1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}