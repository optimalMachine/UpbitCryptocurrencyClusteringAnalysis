{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYosVwSo+CiRzREvZlDP9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/optimalMachine/UpbitCryptocurrencyClusteringAnalysis/blob/main/Upbit_Cryptocurrency_Clustering_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ë¡œê¹… ì„¤ì • - ê¸°ì¡´ ì„¤ì •ê³¼ ì¶©ëŒ ë°©ì§€\n",
        "logger = logging.getLogger(__name__)\n",
        "if not logger.handlers:\n",
        "    handler = logging.StreamHandler()\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.addHandler(handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "# ì˜ì–´ í°íŠ¸ ì„¤ì •\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "def validate_data_continuity(df, market, expected_interval_hours=4):\n",
        "    \"\"\"ë°ì´í„° ì—°ì†ì„± ê²€ì¦ ë° ë³´ê³ \"\"\"\n",
        "    if len(df) < 2:\n",
        "        return True\n",
        "\n",
        "    time_diffs = df.index.to_series().diff()[1:]\n",
        "    expected_diff = pd.Timedelta(hours=expected_interval_hours)\n",
        "\n",
        "    # í—ˆìš© ì˜¤ì°¨ (5%)\n",
        "    tolerance = 0.05\n",
        "    gaps = time_diffs[\n",
        "        (time_diffs < expected_diff * (1 - tolerance)) |\n",
        "        (time_diffs > expected_diff * (1 + tolerance))\n",
        "    ]\n",
        "\n",
        "    if len(gaps) > 0:\n",
        "        logger.warning(f\"{market}: ë¹„ì •ìƒì ì¸ ì‹œê°„ ê°„ê²© {len(gaps)}ê°œ ë°œê²¬\")\n",
        "        # í° ê°­ë§Œ ë³´ê³ \n",
        "        large_gaps = gaps[gaps > expected_diff * 2]\n",
        "        if len(large_gaps) > 0:\n",
        "            logger.warning(f\"{market}: í° ë°ì´í„° ê°­ {len(large_gaps)}ê°œ (2ë°° ì´ìƒ ê°„ê²©)\")\n",
        "\n",
        "    return len(gaps) == 0\n",
        "\n",
        "def get_upbit_candles(market, hours=4320, interval='240'):\n",
        "    \"\"\"\n",
        "    ì—…ë¹„íŠ¸ì—ì„œ íŠ¹ì • ì½”ì¸ì˜ ê³¼ê±° ê°€ê²© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „\n",
        "\n",
        "    Parameters:\n",
        "    - market: ë§ˆì¼“ ì½”ë“œ (ì˜ˆ: 'KRW-BTC')\n",
        "    - hours: ê°€ì ¸ì˜¬ ë°ì´í„° ê¸°ê°„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ê°’: 4320ì‹œê°„ = 180ì¼ = 6ê°œì›”)\n",
        "    - interval: ìº”ë“¤ ê°„ê²© ('1', '3', '5', '15', '10', '30', '60', '240')\n",
        "    \"\"\"\n",
        "\n",
        "    # 4ì‹œê°„ë´‰ = 240ë¶„\n",
        "    url = f\"https://api.upbit.com/v1/candles/minutes/{interval}\"\n",
        "\n",
        "    # APIëŠ” ìµœëŒ€ 200ê°œê¹Œì§€ë§Œ ë°˜í™˜í•˜ë¯€ë¡œ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ í•„ìš”\n",
        "    all_data = []\n",
        "    to_time = None\n",
        "    collected_times = set()  # ì „ì²´ ìˆ˜ì§‘ëœ ì‹œê°„ì„ ì¶”ì \n",
        "\n",
        "    # 4ì‹œê°„ë´‰ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°\n",
        "    total_candles_needed = hours // 4\n",
        "\n",
        "    headers = {\"accept\": \"application/json\"}\n",
        "\n",
        "    # API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ (ìµœëŒ€ 10íšŒ = 2000ê°œ ìº”ë“¤)\n",
        "    max_api_calls = 10\n",
        "    api_calls = 0\n",
        "\n",
        "    while len(all_data) < total_candles_needed and api_calls < max_api_calls:\n",
        "        params = {\n",
        "            'market': market,\n",
        "            'count': min(200, total_candles_needed - len(all_data))\n",
        "        }\n",
        "\n",
        "        if to_time:\n",
        "            params['to'] = to_time\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, params=params, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                if not data:\n",
        "                    break\n",
        "\n",
        "                # ì¤‘ë³µ ì œê±° ë¡œì§ (ê°œì„ ë¨)\n",
        "                new_data = []\n",
        "                for candle in data:\n",
        "                    candle_time = candle['candle_date_time_kst']\n",
        "                    if candle_time not in collected_times:\n",
        "                        new_data.append(candle)\n",
        "                        collected_times.add(candle_time)\n",
        "\n",
        "                if not new_data:\n",
        "                    logger.warning(f\"{market}: ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "                    break\n",
        "\n",
        "                # API ì‘ë‹µ ë°ì´í„° ì •ë ¬ í™•ì¸\n",
        "                if len(new_data) > 1:\n",
        "                    first_time = pd.to_datetime(new_data[0]['candle_date_time_kst'])\n",
        "                    last_time = pd.to_datetime(new_data[-1]['candle_date_time_kst'])\n",
        "\n",
        "                    # ì—…ë¹„íŠ¸ APIëŠ” ë³´í†µ ìµœì‹  ë°ì´í„°ë¶€í„° ë°˜í™˜ (ë‚´ë¦¼ì°¨ìˆœ)\n",
        "                    if first_time > last_time:  # ë‚´ë¦¼ì°¨ìˆœ (ìµœì‹  â†’ ê³¼ê±°)\n",
        "                        to_time = new_data[-1]['candle_date_time_utc']\n",
        "                    else:  # ì˜¤ë¦„ì°¨ìˆœ (ê³¼ê±° â†’ ìµœì‹ ) - ë“œë¬¼ì§€ë§Œ ê°€ëŠ¥\n",
        "                        to_time = new_data[0]['candle_date_time_utc']\n",
        "\n",
        "                all_data.extend(new_data)\n",
        "\n",
        "                # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ëŒ€ê¸°\n",
        "                time.sleep(0.1)\n",
        "                api_calls += 1\n",
        "\n",
        "            else:\n",
        "                logger.warning(f\"API ì˜¤ë¥˜ ({market}): {response.status_code}\")\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error for {market}: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    if all_data:\n",
        "        df = pd.DataFrame(all_data)\n",
        "        df['candle_date_time_kst'] = pd.to_datetime(df['candle_date_time_kst'])\n",
        "        df = df.set_index('candle_date_time_kst')\n",
        "        df = df.sort_index(ascending=True)\n",
        "\n",
        "        # ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±° (ë” ì—„ê²©í•˜ê²Œ)\n",
        "        df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "        # ë°ì´í„° ì—°ì†ì„± ì²´í¬\n",
        "        validate_data_continuity(df, market)\n",
        "\n",
        "        # ìš”ì²­í•œ ê¸°ê°„ë³´ë‹¤ ì ê²Œ ìˆ˜ì§‘ëœ ê²½ìš° ì•Œë¦¼\n",
        "        if len(df) < total_candles_needed * 0.8:  # 80% ë¯¸ë§Œ\n",
        "            print(f\"  {market}: {len(df)}ê°œ ìº”ë“¤ë§Œ ìˆ˜ì§‘ë¨ (ëª©í‘œ: {total_candles_needed}ê°œ)\")\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def calculate_features(returns_df):\n",
        "    \"\"\"ê° ì½”ì¸ì˜ íŠ¹ì„± ê³„ì‚° - ê°œì„ ëœ ë²„ì „\"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    for coin in returns_df.columns:\n",
        "        coin_returns = returns_df[coin].dropna()\n",
        "\n",
        "        # ìµœì†Œ ë°ì´í„° ì²´í¬\n",
        "        if len(coin_returns) < 60:  # 10ì¼ ìµœì†Œ\n",
        "            logger.warning(f\"{coin}: ë°ì´í„° ë¶€ì¡± ({len(coin_returns)}ê°œ)\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # ê¸°ë³¸ í†µê³„\n",
        "            features.loc[coin, 'mean_return'] = coin_returns.mean()\n",
        "            features.loc[coin, 'volatility'] = coin_returns.std()\n",
        "\n",
        "            # Sharpe Ratio ê³„ì‚°\n",
        "            if coin_returns.std() > 1e-8:\n",
        "                features.loc[coin, 'sharpe_ratio'] = (\n",
        "                    coin_returns.mean() / coin_returns.std() * np.sqrt(365 * 6)\n",
        "                )\n",
        "            else:\n",
        "                features.loc[coin, 'sharpe_ratio'] = 0\n",
        "\n",
        "            # ê¸°íƒ€ í†µê³„ëŸ‰\n",
        "            features.loc[coin, 'skewness'] = coin_returns.skew()\n",
        "            features.loc[coin, 'kurtosis'] = coin_returns.kurtosis()\n",
        "            features.loc[coin, 'max_return'] = coin_returns.max()\n",
        "            features.loc[coin, 'min_return'] = coin_returns.min()\n",
        "            features.loc[coin, 'positive_periods_ratio'] = (coin_returns > 0).sum() / len(coin_returns)\n",
        "\n",
        "            # Max Drawdown - ì•ˆì „í•œ ê³„ì‚°\n",
        "            try:\n",
        "                cumulative = (1 + coin_returns).cumprod()\n",
        "                running_max = cumulative.expanding().max()\n",
        "                drawdown = (cumulative - running_max) / running_max\n",
        "                features.loc[coin, 'max_drawdown'] = drawdown.min()\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"{coin}: Max Drawdown ê³„ì‚° ì‹¤íŒ¨\")\n",
        "                features.loc[coin, 'max_drawdown'] = np.nan\n",
        "\n",
        "            # Calmar Ratio\n",
        "            if abs(features.loc[coin, 'max_drawdown']) > 1e-8:\n",
        "                features.loc[coin, 'calmar_ratio'] = (\n",
        "                    features.loc[coin, 'mean_return'] * 365 * 6 / abs(features.loc[coin, 'max_drawdown'])\n",
        "                )\n",
        "            else:\n",
        "                features.loc[coin, 'calmar_ratio'] = 0\n",
        "\n",
        "            # ë™ì  ê¸°ê°„ ê³„ì‚° (ë°ì´í„° ê¸¸ì´ì— ë”°ë¼)\n",
        "            data_len = len(coin_returns)\n",
        "\n",
        "            # ì¼ì¤‘ ë³€ë™ì„± (ìµœì†Œ 6ê°œ í•„ìš”)\n",
        "            if data_len >= 6:\n",
        "                daily_returns = coin_returns.rolling(6).sum().dropna()\n",
        "                if len(daily_returns) > 0:\n",
        "                    features.loc[coin, 'intraday_volatility'] = daily_returns.std()\n",
        "\n",
        "            # ì£¼ê°„ ë³€ë™ì„± (ìµœì†Œ 42ê°œ í•„ìš”)\n",
        "            if data_len >= 42:\n",
        "                weekly_returns = coin_returns.rolling(42).sum().dropna()\n",
        "                if len(weekly_returns) > 0:\n",
        "                    features.loc[coin, 'weekly_volatility'] = weekly_returns.std()\n",
        "\n",
        "            # ì›”ê°„ íŠ¸ë Œë“œ (ìµœì†Œ 180ê°œ í•„ìš”)\n",
        "            if data_len >= 180:\n",
        "                monthly_return = coin_returns.iloc[-180:].sum()\n",
        "                features.loc[coin, 'monthly_trend'] = monthly_return\n",
        "\n",
        "            # ì„¸ì…˜ë³„ ì„±ê³¼ (ìˆ˜ì •ëœ ì•ˆì „í•œ ë²„ì „)\n",
        "            if hasattr(returns_df.index, 'hour') and data_len >= 30:\n",
        "                try:\n",
        "                    # returns_dfì—ì„œ í•´ë‹¹ ì½”ì¸ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œ\n",
        "                    coin_series = returns_df[coin].dropna()\n",
        "\n",
        "                    if len(coin_series) > 0:\n",
        "                        coin_hours = coin_series.index.hour\n",
        "\n",
        "                        # ê° ì„¸ì…˜ì˜ ë°ì´í„° í•„í„°ë§\n",
        "                        asia_data = coin_series[coin_hours.isin([0, 4])]\n",
        "                        europe_data = coin_series[coin_hours.isin([8, 12])]\n",
        "                        us_data = coin_series[coin_hours.isin([16, 20])]\n",
        "\n",
        "                        # ì„¸ì…˜ë³„ ìˆ˜ìµë¥  ê³„ì‚°\n",
        "                        if len(asia_data) > 10:\n",
        "                            features.loc[coin, 'asia_session_return'] = asia_data.mean()\n",
        "                        if len(europe_data) > 10:\n",
        "                            features.loc[coin, 'europe_session_return'] = europe_data.mean()\n",
        "                        if len(us_data) > 10:\n",
        "                            features.loc[coin, 'us_session_return'] = us_data.mean()\n",
        "                except Exception as e:\n",
        "                    logger.debug(f\"{coin}: ì„¸ì…˜ë³„ ì„±ê³¼ ê³„ì‚° ì‹¤íŒ¨ - {str(e)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"{coin} íŠ¹ì„± ê³„ì‚° ì‹¤íŒ¨: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # NaN ê°’ ì²´í¬ ë° ì œê±°\n",
        "    if features.isnull().any().any():\n",
        "        features_before = len(features)\n",
        "        # í•µì‹¬ ì»¬ëŸ¼ì— NaNì´ ìˆëŠ” í–‰ë§Œ ì œê±°\n",
        "        essential_cols = ['mean_return', 'volatility', 'sharpe_ratio']\n",
        "        features = features.dropna(subset=essential_cols)\n",
        "        if features_before > len(features):\n",
        "            print(f\"âš ï¸ í•„ìˆ˜ íŠ¹ì„±ì— NaN ê°’ì´ ìˆëŠ” {features_before - len(features)}ê°œ ì½”ì¸ ì œì™¸\")\n",
        "\n",
        "    return features\n",
        "\n",
        "def classify_coins_by_data_quality(coin_data_info):\n",
        "    \"\"\"ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ì½”ì¸ ë¶„ë¥˜\"\"\"\n",
        "    high_quality = []    # 90% ì´ìƒ (972ê°œ+)\n",
        "    medium_quality = []  # 50-90% (540-972ê°œ)\n",
        "    low_quality = []     # 50% ë¯¸ë§Œ (540ê°œ ë¯¸ë§Œ)\n",
        "\n",
        "    target_candles = 1080  # 6ê°œì›” ëª©í‘œ\n",
        "\n",
        "    for coin, count in coin_data_info.items():\n",
        "        if count >= target_candles * 0.9:\n",
        "            high_quality.append(coin)\n",
        "        elif count >= target_candles * 0.5:\n",
        "            medium_quality.append(coin)\n",
        "        else:\n",
        "            low_quality.append(coin)\n",
        "\n",
        "    return {\n",
        "        'high': high_quality,\n",
        "        'medium': medium_quality,\n",
        "        'low': low_quality\n",
        "    }\n",
        "\n",
        "def get_all_krw_markets():\n",
        "    \"\"\"ì—…ë¹„íŠ¸ì˜ ëª¨ë“  KRW ë§ˆì¼“ ì½”ì¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
        "    url = \"https://api.upbit.com/v1/market/all\"\n",
        "    headers = {\"accept\": \"application/json\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            markets = response.json()\n",
        "            krw_coins = []\n",
        "\n",
        "            for market in markets:\n",
        "                if market['market'].startswith('KRW-'):\n",
        "                    coin_symbol = market['market'].split('-')[1]\n",
        "                    krw_coins.append(coin_symbol)\n",
        "\n",
        "            return krw_coins\n",
        "        else:\n",
        "            return []\n",
        "    except Exception as e:\n",
        "        logger.error(f\"ë§ˆì¼“ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def find_common_index_efficient(returns_data):\n",
        "    \"\"\"ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê³µí†µ ì¸ë±ìŠ¤ ì°¾ê¸°\"\"\"\n",
        "    if not returns_data:\n",
        "        return pd.DatetimeIndex([])\n",
        "\n",
        "    # ì²« ë²ˆì§¸ ì½”ì¸ì˜ ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ\n",
        "    common_dates = None\n",
        "    min_required = 60  # ìµœì†Œ ìš”êµ¬ ë°ì´í„°\n",
        "\n",
        "    for i, (coin, returns) in enumerate(returns_data.items()):\n",
        "        if common_dates is None:\n",
        "            common_dates = set(returns.index)\n",
        "        else:\n",
        "            # êµì§‘í•© ì—…ë°ì´íŠ¸\n",
        "            common_dates &= set(returns.index)\n",
        "\n",
        "        # ê³µí†µ ë‚ ì§œê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ\n",
        "        if len(common_dates) < min_required:\n",
        "            logger.warning(f\"ê³µí†µ ë‚ ì§œê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤: {len(common_dates)}ê°œ (ì²˜ë¦¬ëœ ì½”ì¸: {i+1}ê°œ)\")\n",
        "            break\n",
        "\n",
        "    if common_dates:\n",
        "        return pd.DatetimeIndex(sorted(list(common_dates)))\n",
        "    else:\n",
        "        return pd.DatetimeIndex([])\n",
        "\n",
        "def get_multiple_coins_data(coin_list, hours=4320, max_coins=None):\n",
        "    \"\"\"\n",
        "    ì—¬ëŸ¬ ì½”ì¸ì˜ ë°ì´í„°ë¥¼ í•œë²ˆì— ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „\n",
        "    \"\"\"\n",
        "    returns_data = {}\n",
        "    price_data = {}\n",
        "    failed_coins = []\n",
        "    coin_data_info = {}  # ê° ì½”ì¸ì˜ ë°ì´í„° ê°œìˆ˜ ì €ì¥\n",
        "\n",
        "    # ìµœëŒ€ ì½”ì¸ ìˆ˜ ì œí•œ (ì˜µì…˜)\n",
        "    if max_coins:\n",
        "        coin_list = coin_list[:max_coins]\n",
        "\n",
        "    total_coins = len(coin_list)\n",
        "    print(f\"ì´ {total_coins}ê°œ ì½”ì¸ì˜ 4ì‹œê°„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...\")\n",
        "    print(f\"ìˆ˜ì§‘ ê¸°ê°„: ì•½ {hours//24}ì¼ ({hours}ì‹œê°„) = {hours//24//30:.1f}ê°œì›”\")\n",
        "    print(f\"ì˜ˆìƒ ìº”ë“¤ ìˆ˜: ì•½ {hours//4}ê°œ\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •\n",
        "    batch_size = 20 if total_coins > 100 else min(total_coins, 30)\n",
        "\n",
        "    for batch_start in range(0, total_coins, batch_size):\n",
        "        batch_end = min(batch_start + batch_size, total_coins)\n",
        "        batch_coins = coin_list[batch_start:batch_end]\n",
        "\n",
        "        print(f\"\\në°°ì¹˜ {batch_start//batch_size + 1}/{(total_coins-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘...\")\n",
        "\n",
        "        for idx, coin in enumerate(batch_coins):\n",
        "            global_idx = batch_start + idx\n",
        "            market = f'KRW-{coin}'\n",
        "\n",
        "            # ì§„í–‰ìƒí™© í‘œì‹œ\n",
        "            if (global_idx + 1) % 5 == 0 or global_idx == 0:\n",
        "                print(f\"ì§„í–‰ë¥ : {global_idx+1}/{total_coins} ({(global_idx+1)/total_coins*100:.1f}%)\")\n",
        "\n",
        "            try:\n",
        "                df = get_upbit_candles(market, hours=hours, interval='240')\n",
        "                if df is not None and len(df) > 60:  # ìµœì†Œ 60ê°œ ìº”ë“¤ (10ì¼) ì´ìƒ\n",
        "                    # ë°ì´í„° ì •ë ¬ í™•ì¸\n",
        "                    df = df.sort_index(ascending=True)\n",
        "\n",
        "                    # ìˆ˜ìµë¥  ê³„ì‚°\n",
        "                    returns = df['trade_price'].pct_change().dropna()\n",
        "\n",
        "                    if len(returns) > 60 and returns.std() > 1e-8:\n",
        "                        returns_data[coin] = returns\n",
        "                        price_data[coin] = df['trade_price']\n",
        "                        coin_data_info[coin] = len(returns)\n",
        "                    else:\n",
        "                        failed_coins.append(coin)\n",
        "                else:\n",
        "                    failed_coins.append(coin)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"{coin} ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}\")\n",
        "                failed_coins.append(coin)\n",
        "\n",
        "            # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ëŒ€ê¸°\n",
        "            time.sleep(0.3)\n",
        "\n",
        "        # ë°°ì¹˜ ê°„ ì¶”ê°€ ëŒ€ê¸°\n",
        "        if batch_end < total_coins:\n",
        "            print(f\"ë‹¤ìŒ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸° ì¤‘...\")\n",
        "            time.sleep(3)\n",
        "\n",
        "    print(f\"\\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
        "    print(f\"ì„±ê³µ: {len(returns_data)}ê°œ / ì‹¤íŒ¨: {len(failed_coins)}ê°œ\")\n",
        "\n",
        "    if failed_coins and len(failed_coins) <= 20:\n",
        "        print(f\"ì‹¤íŒ¨í•œ ì½”ì¸: {', '.join(failed_coins)}\")\n",
        "    elif failed_coins:\n",
        "        print(f\"ì‹¤íŒ¨í•œ ì½”ì¸: {', '.join(failed_coins[:20])} ì™¸ {len(failed_coins)-20}ê°œ\")\n",
        "\n",
        "    # ë°ì´í„° í’ˆì§ˆ ë¶„ë¥˜\n",
        "    quality_groups = classify_coins_by_data_quality(coin_data_info)\n",
        "    print(f\"\\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¶„ì„:\")\n",
        "    print(f\"  - ê³ í’ˆì§ˆ (90%+): {len(quality_groups['high'])}ê°œ\")\n",
        "    print(f\"  - ì¤‘í’ˆì§ˆ (50-90%): {len(quality_groups['medium'])}ê°œ\")\n",
        "    print(f\"  - ì €í’ˆì§ˆ (<50%): {len(quality_groups['low'])}ê°œ\")\n",
        "\n",
        "    # DataFrame ìƒì„± - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê³µí†µ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
        "    if returns_data:\n",
        "        # íš¨ìœ¨ì ì¸ ê³µí†µ ì¸ë±ìŠ¤ ê³„ì‚°\n",
        "        common_index = find_common_index_efficient(returns_data)\n",
        "\n",
        "        print(f\"\\nê³µí†µ ì¸ë±ìŠ¤ ê°œìˆ˜: {len(common_index)}\")\n",
        "\n",
        "        # ê³µí†µ ì¸ë±ìŠ¤ë¡œ DataFrame ìƒì„±\n",
        "        returns_dict_aligned = {}\n",
        "        price_dict_aligned = {}\n",
        "\n",
        "        # ìµœì†Œ 360ê°œ ì´ìƒì˜ ê³µí†µ ë°ì´í„° ì„ í˜¸\n",
        "        min_required = 360 if len(common_index) >= 360 else 60\n",
        "\n",
        "        if len(common_index) >= min_required:\n",
        "            for coin, returns in returns_data.items():\n",
        "                try:\n",
        "                    returns_dict_aligned[coin] = returns[common_index]\n",
        "                    if coin in price_data:\n",
        "                        price_dict_aligned[coin] = price_data[coin][common_index]\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"{coin}: ê³µí†µ ì¸ë±ìŠ¤ ì ìš© ì‹¤íŒ¨ - {str(e)}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ê³µí†µ ì¸ë±ìŠ¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(common_index)}ê°œ\")\n",
        "            # ê° ì½”ì¸ë³„ë¡œ ê°€ëŠ¥í•œ ë°ì´í„° ì‚¬ìš©\n",
        "            for coin, returns in returns_data.items():\n",
        "                if len(returns) >= min_required:\n",
        "                    returns_dict_aligned[coin] = returns\n",
        "                    if coin in price_data:\n",
        "                        price_dict_aligned[coin] = price_data[coin]\n",
        "\n",
        "        returns_df = pd.DataFrame(returns_dict_aligned)\n",
        "        price_df = pd.DataFrame(price_dict_aligned)\n",
        "\n",
        "        # ì¸ë±ìŠ¤ ì •ë ¬ ë° ë°ì´í„° ì •ë ¬\n",
        "        returns_df = returns_df.sort_index(ascending=True)\n",
        "        price_df = price_df.sort_index(ascending=True)\n",
        "\n",
        "        # ì»¬ëŸ¼ë„ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬ (ì¬í˜„ì„±ì„ ìœ„í•´)\n",
        "        returns_df = returns_df.reindex(sorted(returns_df.columns), axis=1)\n",
        "        price_df = price_df.reindex(sorted(price_df.columns), axis=1)\n",
        "\n",
        "        print(f\"\\nìˆ˜ì§‘ëœ ê³µí†µ 4ì‹œê°„ë´‰ ê°œìˆ˜: {len(returns_df)}ê°œ\")\n",
        "        if len(returns_df) > 0:\n",
        "            print(f\"ê³µí†µ ìˆ˜ì§‘ ê¸°ê°„: {returns_df.index[0].strftime('%Y-%m-%d %H:%M')} ~ {returns_df.index[-1].strftime('%Y-%m-%d %H:%M')}\")\n",
        "            actual_days = (returns_df.index[-1] - returns_df.index[0]).days\n",
        "            print(f\"ì‹¤ì œ ìˆ˜ì§‘ ì¼ìˆ˜: {actual_days}ì¼ ({actual_days/30:.1f}ê°œì›”)\")\n",
        "    else:\n",
        "        returns_df = pd.DataFrame()\n",
        "        price_df = pd.DataFrame()\n",
        "\n",
        "    return returns_df, price_df, quality_groups\n",
        "\n",
        "def adaptive_clustering(features_df, max_k=10):\n",
        "    \"\"\"ë°ì´í„° íŠ¹ì„±ì— ë§ëŠ” ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° - ìˆ˜ì •ëœ ë²„ì „\"\"\"\n",
        "    n_samples = len(features_df)\n",
        "\n",
        "    # ìƒ˜í”Œ ìˆ˜ì— ë”°ë¼ ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ì¡°ì •\n",
        "    max_k = min(max_k, n_samples // 10)\n",
        "    max_k = max(max_k, 3)\n",
        "\n",
        "    # DataFrameì´ë©´ ì»¬ëŸ¼ ì²´í¬ ê°€ëŠ¥\n",
        "    if isinstance(features_df, pd.DataFrame) and 'volatility' in features_df.columns:\n",
        "        volatility_std = features_df['volatility'].std()\n",
        "        if volatility_std > 0.02:  # ë³€ë™ì„± ì°¨ì´ê°€ í¬ë©´\n",
        "            max_k = min(max_k + 2, n_samples // 8)\n",
        "\n",
        "    return max_k\n",
        "\n",
        "def find_optimal_clusters(features_scaled, features_df=None, max_k=10):\n",
        "    \"\"\"ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° - ê°œì„ ëœ ë²„ì „\"\"\"\n",
        "    n_samples = len(features_scaled)\n",
        "\n",
        "    if features_df is not None:\n",
        "        max_k = adaptive_clustering(features_df, max_k=max_k)\n",
        "    else:\n",
        "        max_k = min(max_k, n_samples // 10)\n",
        "        max_k = max(max_k, 3)\n",
        "\n",
        "    inertias = []\n",
        "    silhouette_scores = []\n",
        "\n",
        "    for k in range(2, max_k+1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        kmeans.fit(features_scaled)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "\n",
        "        # ì•ˆì „í•œ silhouette score ê³„ì‚°\n",
        "        try:\n",
        "            score = silhouette_score(features_scaled, kmeans.labels_)\n",
        "            silhouette_scores.append(score)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Silhouette score ê³„ì‚° ì‹¤íŒ¨ (k={k}): {str(e)}\")\n",
        "            silhouette_scores.append(-1)\n",
        "\n",
        "    return inertias, silhouette_scores\n",
        "\n",
        "def perform_clustering_analysis(returns_df):\n",
        "    \"\"\"í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ìˆ˜í–‰ - ê°œì„ ëœ ë²„ì „\"\"\"\n",
        "\n",
        "    # ë°ì´í„° ê²€ì¦\n",
        "    if returns_df.empty or len(returns_df.columns) < 3:\n",
        "        print(\"âŒ ë¶„ì„í•˜ê¸°ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ 3ê°œ ì´ìƒì˜ ì½”ì¸ í•„ìš”)\")\n",
        "        return None, None\n",
        "\n",
        "    # íŠ¹ì„± ê³„ì‚°\n",
        "    features = calculate_features(returns_df)\n",
        "\n",
        "    # featuresê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸\n",
        "    if features.empty:\n",
        "        print(\"âŒ ìœ íš¨í•œ íŠ¹ì„±ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None, None\n",
        "\n",
        "    # featuresì™€ returns_dfì˜ ì¸ë±ìŠ¤ ì¼ì¹˜ í™•ì¸\n",
        "    common_coins = list(set(returns_df.columns) & set(features.index))\n",
        "    if len(common_coins) < 3:\n",
        "        print(\"âŒ ìœ íš¨í•œ íŠ¹ì„±ì„ ê°€ì§„ ì½”ì¸ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\")\n",
        "        return None, None\n",
        "\n",
        "    # ê³µí†µ ì½”ì¸ë§Œ ì‚¬ìš© (ì •ë ¬í•˜ì—¬ ì¬í˜„ì„± í™•ë³´)\n",
        "    common_coins = sorted(common_coins)\n",
        "    features = features.loc[common_coins]\n",
        "    returns_df = returns_df[common_coins]\n",
        "\n",
        "    # íŠ¹ì„± ì •ê·œí™”\n",
        "    scaler = StandardScaler()\n",
        "    try:\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ íŠ¹ì„± ì •ê·œí™” ì‹¤íŒ¨: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "    # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° - features DataFrame ì „ë‹¬\n",
        "    inertias, silhouette_scores = find_optimal_clusters(features_scaled, features_df=features, max_k=8)\n",
        "\n",
        "    # ì‹œê°í™”ë¥¼ ìœ„í•œ Figure ìƒì„±\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # 1. Elbow Method\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    ax1.plot(range(2, len(inertias)+2), inertias, 'bo-')\n",
        "    ax1.set_xlabel('Number of Clusters')\n",
        "    ax1.set_ylabel('Inertia')\n",
        "    ax1.set_title('Elbow Method')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Silhouette Score\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    valid_scores = [s for s in silhouette_scores if s != -1]\n",
        "    if valid_scores:\n",
        "        ax2.plot(range(2, len(silhouette_scores)+2), silhouette_scores, 'ro-')\n",
        "        ax2.set_xlabel('Number of Clusters')\n",
        "        ax2.set_ylabel('Silhouette Score')\n",
        "        ax2.set_title('Silhouette Score by Number of Clusters')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • (ìˆ˜ì •ëœ ë¡œì§)\n",
        "        if valid_scores:\n",
        "            # silhouette_scoresì—ì„œ ìµœëŒ€ê°’(valid_scoresì˜ ìµœëŒ€ê°’)ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
        "            max_score = max(valid_scores)\n",
        "            optimal_k = silhouette_scores.index(max_score) + 2\n",
        "        else:\n",
        "            optimal_k = 3\n",
        "    else:\n",
        "        optimal_k = 3  # ê¸°ë³¸ê°’\n",
        "        ax2.text(0.5, 0.5, 'Silhouette Score calculation failed', ha='center', va='center')\n",
        "\n",
        "    print(f\"\\nğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ê²°ê³¼:\")\n",
        "    print(\"=\" * 60)\n",
        "    if valid_scores:\n",
        "        print(f\"ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {optimal_k}ê°œ (Silhouette Score: {max(valid_scores):.3f})\")\n",
        "    else:\n",
        "        print(f\"ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {optimal_k}ê°œ (Silhouette Score: N/A)\")\n",
        "\n",
        "    # K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰\n",
        "    try:\n",
        "        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "        clusters = kmeans.fit_predict(features_scaled)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {str(e)}\")\n",
        "        plt.close(fig)\n",
        "        return None, None\n",
        "\n",
        "    # í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ì €ì¥\n",
        "    cluster_df = pd.DataFrame({\n",
        "        'Coin': features.index,\n",
        "        'Cluster': clusters\n",
        "    })\n",
        "\n",
        "    # PCAë¡œ ì°¨ì› ì¶•ì†Œ (ì‹œê°í™”ìš©) - ìˆ˜ì •ëœ ë²„ì „\n",
        "    try:\n",
        "        # ìµœì†Œ 2ê°œ ì´ìƒì˜ íŠ¹ì„±ì´ ìˆì„ ë•Œë§Œ PCA ìˆ˜í–‰\n",
        "        if features.shape[1] >= 2:\n",
        "            n_components = min(2, features.shape[1])\n",
        "            pca = PCA(n_components=n_components)\n",
        "            features_pca = pca.fit_transform(features_scaled)\n",
        "            pca_success = True\n",
        "        else:\n",
        "            # íŠ¹ì„±ì´ 1ê°œì¸ ê²½ìš° ì²˜ë¦¬\n",
        "            pca_success = False\n",
        "            features_pca = np.column_stack([features_scaled[:, 0], np.zeros(len(features_scaled))])\n",
        "            n_components = 1\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"PCA ë³€í™˜ ê²½ê³ : {str(e)}\")\n",
        "        pca_success = False\n",
        "        if features_scaled.shape[1] >= 2:\n",
        "            features_pca = features_scaled[:, :2]\n",
        "        else:\n",
        "            features_pca = np.column_stack([features_scaled[:, 0], np.zeros(len(features_scaled))])\n",
        "        n_components = 1\n",
        "\n",
        "    # 3. í´ëŸ¬ìŠ¤í„° ì‹œê°í™” (PCA) - ìˆ˜ì •ëœ ë²„ì „\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    if features_pca.shape[1] >= 2:\n",
        "        scatter = ax3.scatter(features_pca[:, 0], features_pca[:, 1],\n",
        "                             c=clusters, cmap='viridis', s=200, alpha=0.6)\n",
        "\n",
        "        # ì½”ì¸ ì´ë¦„ í‘œì‹œ (ë§ì€ ê²½ìš° ìƒìœ„ ì½”ì¸ë§Œ)\n",
        "        if len(features.index) > 30:\n",
        "            # ìƒ¤í”„ë¹„ìœ¨ ê¸°ì¤€ ìƒìœ„ 30ê°œ\n",
        "            if 'sharpe_ratio' in features.columns:\n",
        "                top_coins = features.nlargest(30, 'sharpe_ratio').index\n",
        "            else:\n",
        "                top_coins = features.index[:30]\n",
        "\n",
        "            for i, coin in enumerate(features.index):\n",
        "                if coin in top_coins:\n",
        "                    ax3.annotate(coin, (features_pca[i, 0], features_pca[i, 1]),\n",
        "                                fontsize=8, ha='center', va='center')\n",
        "        else:\n",
        "            for i, coin in enumerate(features.index):\n",
        "                ax3.annotate(coin, (features_pca[i, 0], features_pca[i, 1]),\n",
        "                            fontsize=10, ha='center', va='center')\n",
        "\n",
        "        if pca_success and n_components == 2:\n",
        "            ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "            ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "        else:\n",
        "            ax3.set_xlabel('Feature 1')\n",
        "            ax3.set_ylabel('Feature 2')\n",
        "\n",
        "        ax3.set_title('Cryptocurrency Clusters (PCA)')\n",
        "        plt.colorbar(scatter, ax=ax3)\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'PCA visualization not available\\n(Insufficient features)',\n",
        "                ha='center', va='center', fontsize=12)\n",
        "        ax3.set_title('Cryptocurrency Clusters')\n",
        "\n",
        "    # 4. íŠ¹ì„±ë³„ íˆíŠ¸ë§µ\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    features_with_cluster = features.copy()\n",
        "    features_with_cluster['Cluster'] = clusters\n",
        "    features_sorted = features_with_cluster.sort_values('Cluster')\n",
        "\n",
        "    # í‘œì‹œí•  íŠ¹ì„± ì„ íƒ (ì¡´ì¬í•˜ëŠ” íŠ¹ì„±ë§Œ)\n",
        "    display_features = ['mean_return', 'volatility', 'sharpe_ratio', 'skewness',\n",
        "                       'positive_periods_ratio', 'max_drawdown']\n",
        "    display_features = [f for f in display_features if f in features.columns]\n",
        "\n",
        "    # íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°\n",
        "    if display_features and len(features_sorted) > 0:\n",
        "        if len(features_sorted) > 50:\n",
        "            sns.heatmap(features_sorted[display_features].T,\n",
        "                        cmap='coolwarm', center=0,\n",
        "                        xticklabels=False,\n",
        "                        yticklabels=display_features,\n",
        "                        ax=ax4, cbar_kws={'shrink': 0.8})\n",
        "        else:\n",
        "            sns.heatmap(features_sorted[display_features].T,\n",
        "                        cmap='coolwarm', center=0,\n",
        "                        xticklabels=features_sorted.index,\n",
        "                        yticklabels=display_features,\n",
        "                        ax=ax4, cbar_kws={'shrink': 0.8})\n",
        "            plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'No features to display', ha='center', va='center')\n",
        "\n",
        "    ax4.set_title('Feature Heatmap by Coin')\n",
        "\n",
        "    # 5. í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  íŠ¹ì„±\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    if display_features:\n",
        "        cluster_means = features_with_cluster.groupby('Cluster')[display_features].mean()\n",
        "\n",
        "        # ì•ˆì „í•œ ì •ê·œí™”\n",
        "        cluster_means_std = cluster_means.std()\n",
        "        cluster_means_std[cluster_means_std == 0] = 1  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€\n",
        "        cluster_means_normalized = (cluster_means - cluster_means.mean()) / cluster_means_std\n",
        "\n",
        "        sns.heatmap(cluster_means_normalized.T, annot=True, fmt='.2f',\n",
        "                    cmap='RdBu_r', center=0, ax=ax5,\n",
        "                    xticklabels=[f'Cluster {i}' for i in sorted(cluster_df['Cluster'].unique())],\n",
        "                    yticklabels=display_features,\n",
        "                    cbar_kws={'shrink': 0.8})\n",
        "    else:\n",
        "        ax5.text(0.5, 0.5, 'No features to analyze', ha='center', va='center')\n",
        "\n",
        "    ax5.set_title('Normalized Mean Features by Cluster')\n",
        "\n",
        "    # 6. ìˆ˜ìµë¥ -ë³€ë™ì„± ì‚°ì ë„\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    if 'volatility' in features.columns and 'mean_return' in features.columns:\n",
        "        scatter2 = ax6.scatter(features['volatility']*100, features['mean_return']*100,\n",
        "                              c=clusters, cmap='viridis', s=200, alpha=0.6)\n",
        "\n",
        "        # ë ˆì´ë¸” í‘œì‹œ (ê²¹ì¹¨ ë°©ì§€)\n",
        "        if len(features.index) <= 20:\n",
        "            for i, coin in enumerate(features.index):\n",
        "                ax6.annotate(coin, (features['volatility'].iloc[i]*100,\n",
        "                                   features['mean_return'].iloc[i]*100),\n",
        "                            fontsize=9, ha='left', va='bottom')\n",
        "        else:\n",
        "            # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ëŒ€í‘œ ì½”ì¸ë§Œ í‘œì‹œ\n",
        "            for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "                cluster_coins = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "                if len(cluster_coins) > 0:\n",
        "                    cluster_features = features.loc[cluster_coins]\n",
        "                    if len(cluster_features) > 0 and 'sharpe_ratio' in cluster_features.columns:\n",
        "                        best_coin = cluster_features.nlargest(1, 'sharpe_ratio').index[0]\n",
        "                        idx = features.index.get_loc(best_coin)\n",
        "                        ax6.annotate(best_coin,\n",
        "                                   (features['volatility'].iloc[idx]*100,\n",
        "                                    features['mean_return'].iloc[idx]*100),\n",
        "                                   fontsize=9, ha='left', va='bottom',\n",
        "                                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "        ax6.set_xlabel('4H Volatility (%)')\n",
        "        ax6.set_ylabel('Mean 4H Return (%)')\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter2, ax=ax6)\n",
        "    else:\n",
        "        ax6.text(0.5, 0.5, 'Risk-return data not available', ha='center', va='center')\n",
        "\n",
        "    ax6.set_title('Risk-Return Profile by Cluster')\n",
        "\n",
        "    # 7. í´ëŸ¬ìŠ¤í„°ë³„ ë°•ìŠ¤í”Œë¡¯ (ìˆ˜ìµë¥ )\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    cluster_returns_list = []\n",
        "    cluster_labels = []\n",
        "\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        coins_in_cluster = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        valid_coins = [coin for coin in coins_in_cluster if coin in returns_df.columns]\n",
        "\n",
        "        if valid_coins:\n",
        "            cluster_data = []\n",
        "            for coin in valid_coins:\n",
        "                coin_returns = returns_df[coin].dropna().values\n",
        "                if len(coin_returns) > 0:\n",
        "                    cluster_data.extend(coin_returns)\n",
        "\n",
        "            if cluster_data:\n",
        "                cluster_returns_list.append(cluster_data)\n",
        "                cluster_labels.append(f'Cluster {cluster}')\n",
        "\n",
        "    if cluster_returns_list:\n",
        "        bp = ax7.boxplot(cluster_returns_list, labels=cluster_labels, patch_artist=True)\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(cluster_returns_list)))\n",
        "        for patch, color in zip(bp['boxes'], colors):\n",
        "            patch.set_facecolor(color)\n",
        "        ax7.set_ylabel('4H Returns')\n",
        "        ax7.set_title('Returns Distribution by Cluster')\n",
        "        ax7.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax7.text(0.5, 0.5, 'No data available', ha='center', va='center')\n",
        "        ax7.set_title('Returns Distribution by Cluster')\n",
        "\n",
        "    # 8. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ (í´ëŸ¬ìŠ¤í„°ë³„ ì •ë ¬)\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    valid_coins = [coin for coin in cluster_df['Coin'].values if coin in returns_df.columns]\n",
        "    cluster_df_valid = cluster_df[cluster_df['Coin'].isin(valid_coins)]\n",
        "\n",
        "    if len(cluster_df_valid) > 0:\n",
        "        sorted_coins = cluster_df_valid.sort_values('Cluster')['Coin'].values\n",
        "        corr_sorted = returns_df[sorted_coins].corr()\n",
        "\n",
        "        # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°\n",
        "        if len(sorted_coins) > 30:\n",
        "            sns.heatmap(corr_sorted, cmap='coolwarm', center=0,\n",
        "                        square=True, ax=ax8,\n",
        "                        xticklabels=False, yticklabels=False,\n",
        "                        cbar_kws={'shrink': 0.8})\n",
        "        else:\n",
        "            mask = np.zeros_like(corr_sorted, dtype=bool)\n",
        "            mask[np.triu_indices_from(mask, k=1)] = True\n",
        "            sns.heatmap(corr_sorted, mask=mask, cmap='coolwarm', center=0,\n",
        "                        square=True, ax=ax8,\n",
        "                        xticklabels=sorted_coins, yticklabels=sorted_coins,\n",
        "                        cbar_kws={'shrink': 0.8})\n",
        "            plt.setp(ax8.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "            plt.setp(ax8.yaxis.get_majorticklabels(), rotation=0)\n",
        "\n",
        "        ax8.set_title('Correlation Matrix (Sorted by Cluster)')\n",
        "    else:\n",
        "        ax8.text(0.5, 0.5, 'No data available', ha='center', va='center')\n",
        "        ax8.set_title('Correlation Matrix')\n",
        "\n",
        "    # 9. í´ëŸ¬ìŠ¤í„° í¬ê¸° íŒŒì´ ì°¨íŠ¸\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    cluster_sizes = cluster_df['Cluster'].value_counts().sort_index()\n",
        "\n",
        "    if len(cluster_sizes) > 0:\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(cluster_sizes)))\n",
        "\n",
        "        # ì˜¬ë°”ë¥¸ í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ì™€ í¬ê¸° ì‚¬ìš©\n",
        "        labels = [f'Cluster {cluster_num}\\n({size} coins)'\n",
        "                 for cluster_num, size in cluster_sizes.items()]\n",
        "\n",
        "        wedges, texts, autotexts = ax9.pie(cluster_sizes.values,\n",
        "                                            labels=labels,\n",
        "                                            autopct='%1.1f%%',\n",
        "                                            startangle=90,\n",
        "                                            colors=colors)\n",
        "\n",
        "        # í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ì¡°ì •\n",
        "        for text in texts:\n",
        "            text.set_fontsize(10)\n",
        "        for autotext in autotexts:\n",
        "            autotext.set_color('white')\n",
        "            autotext.set_fontsize(9)\n",
        "            autotext.set_weight('bold')\n",
        "    else:\n",
        "        ax9.text(0.5, 0.5, 'No clusters to display', ha='center', va='center')\n",
        "\n",
        "    ax9.set_title('Cluster Size Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "\n",
        "    # í´ëŸ¬ìŠ¤í„°ë³„ ìƒì„¸ ì •ë³´ ì¶œë ¥\n",
        "    print(\"\\nğŸ” í´ëŸ¬ìŠ¤í„°ë³„ ì½”ì¸ ê·¸ë£¹:\")\n",
        "    print(\"=\" * 60)\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        coins_in_cluster = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        print(f\"\\ní´ëŸ¬ìŠ¤í„° {cluster} ({len(coins_in_cluster)}ê°œ ì½”ì¸):\")\n",
        "\n",
        "        if len(coins_in_cluster) <= 20:\n",
        "            print(f\"  ì½”ì¸: {', '.join(coins_in_cluster)}\")\n",
        "        else:\n",
        "            print(f\"  ì½”ì¸: {', '.join(coins_in_cluster[:10])} ... ì™¸ {len(coins_in_cluster)-10}ê°œ\")\n",
        "\n",
        "        # í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ìš”ì•½\n",
        "        if len(coins_in_cluster) > 0:\n",
        "            valid_coins = [coin for coin in coins_in_cluster if coin in features.index]\n",
        "            if valid_coins:\n",
        "                cluster_features = features.loc[valid_coins].mean()\n",
        "                print(f\"  - í‰ê·  4ì‹œê°„ ìˆ˜ìµë¥ : {cluster_features['mean_return']*100:.4f}%\")\n",
        "                print(f\"  - í‰ê·  ë³€ë™ì„±: {cluster_features['volatility']*100:.4f}%\")\n",
        "                print(f\"  - í‰ê·  ìƒ¤í”„ ë¹„ìœ¨: {cluster_features['sharpe_ratio']:.4f}\")\n",
        "                print(f\"  - í‰ê·  ì–‘ì˜ ìˆ˜ìµ êµ¬ê°„ ë¹„ìœ¨: {cluster_features['positive_periods_ratio']*100:.1f}%\")\n",
        "                if 'max_drawdown' in cluster_features and not np.isnan(cluster_features['max_drawdown']):\n",
        "                    print(f\"  - í‰ê·  ìµœëŒ€ ë‚™í­: {cluster_features['max_drawdown']*100:.2f}%\")\n",
        "                if 'intraday_volatility' in cluster_features and not np.isnan(cluster_features['intraday_volatility']):\n",
        "                    print(f\"  - í‰ê·  ì¼ì¤‘ ë³€ë™ì„±: {cluster_features['intraday_volatility']*100:.2f}%\")\n",
        "\n",
        "    # íŠ¹ì„± ì¤‘ìš”ë„\n",
        "    if pca_success and n_components >= 2:\n",
        "        print(\"\\nğŸ“ˆ í´ëŸ¬ìŠ¤í„° êµ¬ë¶„ì— ì¤‘ìš”í•œ íŠ¹ì„±:\")\n",
        "        print(\"=\" * 60)\n",
        "        feature_importance = np.abs(pca.components_).mean(axis=0)\n",
        "        feature_names = list(features.columns)\n",
        "        if len(feature_names) == len(feature_importance):\n",
        "            importance_df = pd.DataFrame({\n",
        "                'Feature': feature_names,\n",
        "                'Importance': feature_importance\n",
        "            }).sort_values('Importance', ascending=False)\n",
        "\n",
        "            for idx, row in importance_df.head(8).iterrows():\n",
        "                print(f\"  {row['Feature']}: {row['Importance']:.3f}\")\n",
        "\n",
        "    return cluster_df, features\n",
        "\n",
        "# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ\n",
        "if __name__ == \"__main__\":\n",
        "    # ëª¨ë“  KRW ë§ˆì¼“ ì½”ì¸ ê°€ì ¸ì˜¤ê¸°\n",
        "    print(\"ì—…ë¹„íŠ¸ KRW ë§ˆì¼“ ì½”ì¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
        "    all_krw_coins = get_all_krw_markets()\n",
        "\n",
        "    if not all_krw_coins:\n",
        "        print(\"âŒ KRW ë§ˆì¼“ ì½”ì¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\nğŸ“Š ì—…ë¹„íŠ¸ KRW ë§ˆì¼“ ë¶„ì„\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"ì´ KRW ë§ˆì¼“ ì½”ì¸ ìˆ˜: {len(all_krw_coins)}ê°œ\")\n",
        "\n",
        "    # ë¶„ì„ ì˜µì…˜ ì„ íƒ\n",
        "    print(\"\\në¶„ì„ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:\")\n",
        "    print(\"1. ì „ì²´ ì½”ì¸ ë¶„ì„ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)\")\n",
        "    print(\"2. ìƒìœ„ Nê°œ ì½”ì¸ë§Œ ë¶„ì„\")\n",
        "    print(\"3. ì£¼ìš” ì½”ì¸ë§Œ ë¶„ì„ (ì¶”ì²œ)\")\n",
        "\n",
        "    # ê¸°ë³¸ê°’: ì „ì²´ ì½”ì¸ ë¶„ì„\n",
        "    choice = input(\"\\nì„ íƒ (ê¸°ë³¸ê°’: 3): \").strip() or \"3\"\n",
        "\n",
        "    if choice == \"1\":\n",
        "        coin_list = all_krw_coins\n",
        "        print(f\"\\nì „ì²´ {len(coin_list)}ê°œ ì½”ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
        "    elif choice == \"2\":\n",
        "        n = int(input(\"ë¶„ì„í•  ì½”ì¸ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 50): \"))\n",
        "        coin_list = all_krw_coins[:n]\n",
        "        print(f\"\\nìƒìœ„ {n}ê°œ ì½”ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
        "    else:\n",
        "        # ì£¼ìš” ì½”ì¸ ëª©ë¡ (ê±°ë˜ëŸ‰ ìƒìœ„ + ì¸ê¸° ì½”ì¸)\n",
        "        major_coins = ['BTC', 'ETH', 'XRP', 'ADA', 'SOL', 'DOGE', 'AVAX', 'MATIC',\n",
        "                      'LINK', 'DOT', 'ATOM', 'UNI', 'BCH', 'LTC', 'ETC', 'ALGO',\n",
        "                      'SAND', 'MANA', 'AXS', 'THETA', 'EOS', 'TRX', 'XLM', 'VET',\n",
        "                      'HBAR', 'EGLD', 'NEAR', 'FLOW', 'CHZ', 'ENJ', 'QTUM', 'NEO']\n",
        "        coin_list = [coin for coin in major_coins if coin in all_krw_coins]\n",
        "        print(f\"\\nì£¼ìš” {len(coin_list)}ê°œ ì½”ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    # ê³¼ê±° ë°ì´í„° ê¸°ê°„ ì„¤ì • (4ì‹œê°„ë´‰ ê¸°ì¤€)\n",
        "    hours = 4320  # 180ì¼ = 4320ì‹œê°„ = 6ê°œì›”\n",
        "\n",
        "    print(f\"\\nì—…ë¹„íŠ¸ì—ì„œ {hours}ì‹œê°„({hours//24}ì¼ = {hours//24//30:.1f}ê°œì›”)ê°„ì˜ 4ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\")\n",
        "    print(f\"ì˜ˆìƒ ë°ì´í„° í¬ì¸íŠ¸: ì•½ {hours//4}ê°œ (180ì¼ Ã— 6ê°œ/ì¼)\")\n",
        "\n",
        "    # ë°ì´í„° ìˆ˜ì§‘ - ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©\n",
        "    returns_df, price_df, quality_groups = get_multiple_coins_data(coin_list, hours=hours)\n",
        "\n",
        "    if returns_df is None or returns_df.empty:\n",
        "        print(\"âŒ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\nâœ… ë¶„ì„ ê°€ëŠ¥í•œ ì½”ì¸ ìˆ˜: {len(returns_df.columns)}ê°œ\")\n",
        "    print(f\"ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ê°„: {returns_df.index[0].strftime('%Y-%m-%d %H:%M')} ~ {returns_df.index[-1].strftime('%Y-%m-%d %H:%M')}\")\n",
        "    print(f\"ì´ 4ì‹œê°„ë´‰ ê°œìˆ˜: {len(returns_df)}ê°œ\")\n",
        "\n",
        "    # í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ìˆ˜í–‰\n",
        "    cluster_df, features = perform_clustering_analysis(returns_df)\n",
        "\n",
        "    if cluster_df is None or features is None:\n",
        "        print(\"âŒ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "        exit()\n",
        "\n",
        "    # í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ì½”ì¸ ì¶”ì²œ\n",
        "    print(\"\\nğŸ¯ í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ì½”ì¸ ì¶”ì²œ:\")\n",
        "    print(\"=\" * 60)\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        cluster_coins = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        valid_coins = [coin for coin in cluster_coins if coin in features.index]\n",
        "\n",
        "        if valid_coins:\n",
        "            cluster_features = features.loc[valid_coins]\n",
        "\n",
        "            # ìƒ¤í”„ ë¹„ìœ¨ì´ ë†’ì€ ìƒìœ„ 3ê°œ ì½”ì¸\n",
        "            top_coins = cluster_features.nlargest(min(3, len(cluster_features)), 'sharpe_ratio')\n",
        "            print(f\"\\ní´ëŸ¬ìŠ¤í„° {cluster} ì¶”ì²œ ì½”ì¸:\")\n",
        "            for coin in top_coins.index:\n",
        "                sharpe = top_coins.loc[coin, 'sharpe_ratio']\n",
        "                volatility = top_coins.loc[coin, 'volatility'] * 100\n",
        "                mean_return = top_coins.loc[coin, 'mean_return'] * 100\n",
        "                print(f\"  - {coin}: ìƒ¤í”„ë¹„ìœ¨ {sharpe:.3f}, 4ì‹œê°„ ìˆ˜ìµë¥  {mean_return:.3f}%, ë³€ë™ì„± {volatility:.3f}%\")\n",
        "\n",
        "    # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì œì•ˆ\n",
        "    print(\"\\nğŸ’¡ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì œì•ˆ:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"1. ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ìƒ¤í”„ ë¹„ìœ¨ì´ ë†’ì€ 1-2ê°œ ì½”ì¸ ì„ íƒ\")\n",
        "    print(\"2. ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ì˜ 5-10ê°œ ì½”ì¸ìœ¼ë¡œ êµ¬ì„±\")\n",
        "    print(\"3. BTCì™€ ETHëŠ” ì•ˆì •ì„±ì„ ìœ„í•´ í¬í•¨ ê¶Œì¥\")\n",
        "    print(\"4. ê° ì½”ì¸ì˜ ë¹„ì¤‘ì€ ë¦¬ìŠ¤í¬ í—ˆìš©ë„ì— ë”°ë¼ ì¡°ì •\")\n",
        "\n",
        "    # ì¶”ê°€ ë¶„ì„: í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì˜ˆì‹œ\n",
        "    print(\"\\nğŸ² ìƒ˜í”Œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±:\")\n",
        "    print(\"=\" * 60)\n",
        "    sample_portfolio = []\n",
        "\n",
        "    for cluster in sorted(cluster_df['Cluster'].unique()):\n",
        "        cluster_coins = cluster_df[cluster_df['Cluster'] == cluster]['Coin'].values\n",
        "        valid_coins = [coin for coin in cluster_coins if coin in features.index]\n",
        "\n",
        "        if valid_coins:\n",
        "            cluster_features = features.loc[valid_coins]\n",
        "            # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ ìƒ¤í”„ë¹„ìœ¨ ìµœê³  ì½”ì¸ ì„ íƒ\n",
        "            best_coin = cluster_features.nlargest(1, 'sharpe_ratio').index[0]\n",
        "            sample_portfolio.append(best_coin)\n",
        "\n",
        "    # BTC, ETHê°€ ì—†ìœ¼ë©´ ì¶”ê°€\n",
        "    if 'BTC' in returns_df.columns and 'BTC' not in sample_portfolio:\n",
        "        sample_portfolio.insert(0, 'BTC')\n",
        "    if 'ETH' in returns_df.columns and 'ETH' not in sample_portfolio:\n",
        "        sample_portfolio.insert(1, 'ETH')\n",
        "\n",
        "    # ìµœëŒ€ 10ê°œë¡œ ì œí•œ\n",
        "    sample_portfolio = sample_portfolio[:10]\n",
        "\n",
        "    print(f\"ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ({len(sample_portfolio)}ê°œ ì½”ì¸):\")\n",
        "    total_sharpe = 0\n",
        "    for i, coin in enumerate(sample_portfolio):\n",
        "        if coin in features.index:\n",
        "            sharpe = features.loc[coin, 'sharpe_ratio']\n",
        "            volatility = features.loc[coin, 'volatility'] * 100\n",
        "            total_sharpe += sharpe\n",
        "            print(f\"  {i+1}. {coin} (ìƒ¤í”„ë¹„ìœ¨: {sharpe:.3f}, ë³€ë™ì„±: {volatility:.2f}%)\")\n",
        "\n",
        "    if len(sample_portfolio) > 0:\n",
        "        print(f\"\\ní¬íŠ¸í´ë¦¬ì˜¤ í‰ê·  ìƒ¤í”„ë¹„ìœ¨: {total_sharpe/len(sample_portfolio):.3f}\")\n",
        "\n",
        "    # ë¶„ì„ ê²°ê³¼ ì €ì¥ ì˜µì…˜\n",
        "    save = input(\"\\në¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \").strip().lower()\n",
        "    if save == 'y':\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "        try:\n",
        "            # í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ì €ì¥\n",
        "            cluster_df.to_csv(f'upbit_clustering_result_{timestamp}.csv',\n",
        "                             index=False, encoding='utf-8-sig')\n",
        "\n",
        "            # íŠ¹ì„± ë°ì´í„° ì €ì¥\n",
        "            features.to_csv(f'upbit_coin_features_{timestamp}.csv',\n",
        "                           encoding='utf-8-sig')\n",
        "\n",
        "            # ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤ ì €ì¥\n",
        "            portfolio_df = pd.DataFrame({\n",
        "                'Rank': range(1, len(sample_portfolio)+1),\n",
        "                'Coin': sample_portfolio,\n",
        "                'Sharpe_Ratio': [features.loc[coin, 'sharpe_ratio'] if coin in features.index else np.nan\n",
        "                               for coin in sample_portfolio],\n",
        "                '4H_Return_%': [features.loc[coin, 'mean_return']*100 if coin in features.index else np.nan\n",
        "                                 for coin in sample_portfolio],\n",
        "                '4H_Volatility_%': [features.loc[coin, 'volatility']*100 if coin in features.index else np.nan\n",
        "                                     for coin in sample_portfolio]\n",
        "            })\n",
        "            portfolio_df.to_csv(f'upbit_recommended_portfolio_{timestamp}.csv',\n",
        "                              index=False, encoding='utf-8-sig')\n",
        "\n",
        "            print(f\"\\nâœ… ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
        "            print(f\"  - í´ëŸ¬ìŠ¤í„° ê²°ê³¼: upbit_clustering_result_{timestamp}.csv\")\n",
        "            print(f\"  - ì½”ì¸ íŠ¹ì„±: upbit_coin_features_{timestamp}.csv\")\n",
        "            print(f\"  - ì¶”ì²œ í¬íŠ¸í´ë¦¬ì˜¤: upbit_recommended_portfolio_{timestamp}.csv\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "            print(f\"\\nâŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "\n",
        "    print(\"\\nğŸ“Œ ë¶„ì„ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "GRGQZPtcElaJ",
        "outputId": "ff5991c9-755c-4330-b534-06e7aeeea81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì—…ë¹„íŠ¸ KRW ë§ˆì¼“ ì½”ì¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
            "\n",
            "ğŸ“Š ì—…ë¹„íŠ¸ KRW ë§ˆì¼“ ë¶„ì„\n",
            "============================================================\n",
            "ì´ KRW ë§ˆì¼“ ì½”ì¸ ìˆ˜: 179ê°œ\n",
            "\n",
            "ë¶„ì„ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:\n",
            "1. ì „ì²´ ì½”ì¸ ë¶„ì„ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)\n",
            "2. ìƒìœ„ Nê°œ ì½”ì¸ë§Œ ë¶„ì„\n",
            "3. ì£¼ìš” ì½”ì¸ë§Œ ë¶„ì„ (ì¶”ì²œ)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-313239679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;31m# ê¸°ë³¸ê°’: ì „ì²´ ì½”ì¸ ë¶„ì„\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nì„ íƒ (ê¸°ë³¸ê°’: 3): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qxyCYbOE9z1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}